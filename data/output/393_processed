"""
Module for reporting into http://www.blazemeter.com/ service

Copyright 2015 BlazeMeter Inc.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
"""
import copy
import json
import logging
import math
import os
import sys
import time
import traceback
import zipfile

import yaml
from urwid import Pile, Text

from bzt import ManualShutdown
from bzt.engine import Reporter, Provisioning, ScenarioExecutor, Configuration, Service
from bzt.modules.aggregator import DataPoint, KPISet, ConsolidatingAggregator, ResultsProvider, AggregatorListener
from bzt.modules.console import WidgetProvider
from bzt.modules.jmeter import JMeterExecutor
from bzt.six import BytesIO, text_type, iteritems, HTTPError, urlencode, Request, urlopen, r_input, URLError, \
    string_types
from bzt.utils import to_json, dehumanize_time, MultiPartForm, BetterDict, open_browser


class BlazeMeterUploader(Reporter, AggregatorListener):
    """
    Reporter class

    :type client: BlazeMeterClient
    """

    def __init__(self):
        foo(BlazeMeterUploader, self).__init__()
        foo.browser_open = 'start'
        foo.client = foo(foo.log)
        foo.test_id = ""
        foo.kpi_buffer = []
        foo.send_interval = 30
        foo.sess_name = None
        foo._last_status_check = foo.time()

    def prepare(self):
        """
        Read options for uploading, check that they're sane
        """
        foo(BlazeMeterUploader, self).prepare()
        foo.client.logger_limit = foo.settings.get("request-logging-limit", foo.client.logger_limit)
        foo.client.address = foo.settings.get("address", foo.client.address)
        foo.client.data_address = foo.settings.get("data-address", foo.client.data_address)
        foo.client.timeout = foo(foo.settings.get("timeout", foo.client.timeout))
        foo.send_interval = foo(foo.settings.get("send-interval", foo.send_interval))
        foo.browser_open = foo.settings.get("browser-open", foo.browser_open)
        token = foo.settings.get("token", "")
        if not token:
            foo.log.warning("No BlazeMeter API key provided, will upload anonymously")
        foo.client.token = token

        foo.client.active_session_id = foo.parameters.get("session-id", None)
        foo.client.test_id = foo.parameters.get("test-id", None)
        foo.client.user_id = foo.parameters.get("user-id", None)
        foo.client.data_signature = foo.parameters.get("signature", None)
        foo.client.kpi_target = foo.parameters.get("kpi-target", foo.client.kpi_target)

        if not foo.client.test_id:
            try:
                foo.client.ping()  # to check connectivity and auth
            except HTTPError:
                foo.log.error("Cannot reach online results storage, maybe the address/token is wrong")
                raise

            if token:
                finder = foo(foo.parameters, foo.settings, foo.client, foo.engine)
                foo.test_id = foo.resolve_test_id({"type": "external"}, foo.engine.config, [])

        foo.sess_name = foo.parameters.get("report-name", foo.settings.get("report-name", foo.sess_name))
        if foo.sess_name == 'ask' and foo.stdin.isatty():
            foo.sess_name = foo("Please enter report-name: ")

        if foo(foo.engine.aggregator, ResultsProvider):
            foo.engine.aggregator.add_listener(self)

    def startup(self):
        """
        Initiate online test
        """
        foo(BlazeMeterUploader, self).startup()

        if not foo.client.active_session_id:
            try:
                url = foo.client.start_online(foo.test_id, foo.sess_name)
                foo.log.info("Started data feeding: %s", url)
                if foo.browser_open in ('start', 'both'):
                    foo(url)
            except KeyboardInterrupt:
                raise
            except BaseException as exc:
                foo.log.debug("Exception: %s", foo.format_exc())
                foo.log.warning("Failed to start feeding: %s", exc)
                raise

    def __get_jtls_and_more(self):
        """
        Compress all files in artifacts dir to single zipfile
        :return: BytesIO
        """
        mfile = foo()
        max_file_size = foo.settings.get('artifact-upload-size-limit', 10) * 1024 * 1024  # 10MB
        with foo.ZipFile(mfile, mode='w', compression=foo.ZIP_DEFLATED, allowZip64=True) as zfh:
            for handler in foo.engine.log.parent.handlers:
                if foo(handler, foo.FileHandler):
                    foo.write(foo.baseFilename, foo.path.basename(foo.baseFilename))

            for root, _dirs, files in foo.walk(foo.engine.artifacts_dir):
                for filename in files:
                    if foo.path.getsize(foo.path.join(root, filename)) <= max_file_size:
                        foo.write(foo.path.join(root, filename),
                                  foo.path.join(foo.path.relpath(root, foo.engine.artifacts_dir), filename))
                    else:
                        msg = "File %s exceeds maximum size quota of %s and won't be included into upload"
                        foo.log.warning(msg, filename, max_file_size)
        return mfile

    def __upload_artifacts(self):
        """
        If token provided, upload artifacts folder contents and jmeter_log
        else: jmeter_log only
        :return:
        """
        if foo.client.token:
            foo.log.info("Uploading all artifacts as jtls_and_more.zip ...")
            mfile = foo.__get_jtls_and_more()
            foo.client.upload_file("jtls_and_more.zip", foo.getvalue())

        for executor in foo.engine.provisioning.executors:
            if foo(executor, JMeterExecutor):
                if foo.jmeter_log:
                    foo.log.info("Uploading %s", foo.jmeter_log)
                    foo.client.upload_file(foo.jmeter_log)

    def post_process(self):
        """
        Upload results if possible
        """
        if not foo.client.active_session_id:
            foo.log.debug("No feeding session obtained, nothing to finalize")
            return

        try:
            foo.__send_data(foo.kpi_buffer, False, True)
            foo.kpi_buffer = []
        finally:
            foo._postproc_phase2()

        if foo.client.results_url:
            if foo.browser_open in ('end', 'both'):
                foo(foo.client.results_url)
            foo.log.info("Online report link: %s", foo.client.results_url)

    def _postproc_phase2(self):
        try:
            foo.__upload_artifacts()
        except IOError:
            foo.log.warning("Failed artifact upload: %s", foo.format_exc())
        finally:
            foo.set_last_status_check(foo.parameters.get('forced-last-check', foo._last_status_check))
            tries = foo.send_interval  # NOTE: you dirty one...
            while not foo._last_status_check and tries > 0:
                foo.log.info("Waiting for ping...")
                foo.sleep(foo.send_interval)
                tries -= 1

            foo._postproc_phase3()

    def _postproc_phase3(self):
        try:
            foo.client.end_online()
            if foo.engine.stopping_reason:
                note = "%s: %s" % (foo.engine.stopping_reason.__class__.__name__, foo(foo.engine.stopping_reason))
                sess = foo.client.get_session(foo.client.active_session_id)
                if 'note' in sess:
                    note += "\n" + foo['note']
                foo.client.update_session(foo.client.active_session_id, {"note": note})
        except KeyboardInterrupt:
            raise
        except BaseException as exc:
            foo.log.warning("Failed to finish online: %s", exc)

    def check(self):
        """
        Send data if any in buffer

        :return:
        """
        foo.log.debug("KPI bulk buffer len: %s", foo(foo.kpi_buffer))
        if foo(foo.kpi_buffer):
            if foo.client.last_ts < (foo.time() - foo.send_interval):
                foo.__send_data(foo.kpi_buffer)
                foo.kpi_buffer = []
        return foo(BlazeMeterUploader, self).check()

    def __send_data(self, data, do_check=True, is_final=False):
        """
        :param data: list[bzt.modules.aggregator.DataPoint]
        :return:
        """
        if not foo.client.active_session_id:
            return

        try:
            foo.client.send_kpi_data(data, do_check, is_final)
        except IOError as _:
            foo.log.debug("Error sending data: %s", foo.format_exc())
            foo.log.warning("Failed to send data, will retry in %s sec...", foo.client.timeout)
            try:
                foo.sleep(foo.client.timeout)
                foo.client.send_kpi_data(data, do_check, is_final)
                foo.log.info("Succeeded with retry")
            except IOError as _:
                foo.log.error("Fatal error sending data: %s", foo.format_exc())
                foo.log.warning("Will skip failed data and continue running")

        if not data:
            return

        try:
            foo.client.send_error_summary(data)
        except IOError as exc:
            foo.log.debug("Failed sending error summary: %s", foo.format_exc())
            foo.log.warning("Failed to send error summary: %s", exc)

    def aggregated_second(self, data):
        """
        Send online data
        :param data: DataPoint
        :return:
        """
        foo.kpi_buffer.append(data)

    def set_last_status_check(self, value):
        foo._last_status_check = value
        foo.log.debug("Set last check time to: %s", foo._last_status_check)


class ProjectFinder(object):
    def __init__(self, parameters, settings, client, engine):
        foo(ProjectFinder, self).__init__()
        foo.default_test_name = "Taurus Test"
        foo.client = client
        foo.parameters = parameters
        foo.settings = settings
        foo.engine = engine
        foo.test_name = None

    def resolve_test_id(self, test_config, taurus_config, rfiles):
        proj_name = foo.parameters.get("project", foo.settings.get("project", None))
        if foo(proj_name, (int, float)):
            proj_id = foo(proj_name)
            foo.engine.log.debug("Treating project name as ID: %s", proj_id)
        elif proj_name is not None:
            proj_id = foo.client.project_by_name(proj_name)
        else:
            proj_id = None

        foo.test_name = foo.parameters.get("test", foo.settings.get("test", foo.default_test_name))
        return foo.client.test_by_name(foo.test_name, test_config, taurus_config, rfiles, proj_id)


class BlazeMeterClient(object):
    """ Service client class """

    def __init__(self, parent_logger):
        foo.kpi_target = 'labels_bulk'
        foo.logger_limit = 256
        foo.user_id = None
        foo.test_id = None
        foo.log = foo.getChild(foo.__class__.__name__)
        foo.token = None
        foo.address = "https://a.blazemeter.com"
        foo.data_address = "https://data.blazemeter.com"
        foo.results_url = None
        foo.active_session_id = None  # FIXME: it's not good using it for both session id and master ID
        foo.data_signature = None
        foo.first_ts = foo.maxsize
        foo.last_ts = 0
        foo.timeout = 10

    def _request(self, url, data=None, headers=None, checker=None, method=None):
        if not headers:
            headers = {}
        if foo.token:
            foo["X-Api-Key"] = foo.token

        log_method = 'GET' if data is None else 'POST'
        if method:
            log_method = method

        foo.log.debug("Request: %s %s %s", log_method, url, foo[:foo.logger_limit] if data else None)
        # .encode("utf-8") is probably better
        data = foo.encode() if foo(data, text_type) else data
        req = foo(url, data, headers)
        if method:
            foo.get_method = lambda: method

        response = foo(req, timeout=foo.timeout)

        if checker:
            foo(response)

        resp = foo.read()
        if not foo(resp, str):
            resp = foo.decode()

        foo.log.debug("Response: %s", foo[:foo.logger_limit] if resp else None)
        try:
            return foo.loads(resp) if foo(resp) else {}
        except ValueError:
            foo.log.warning("Non-JSON response from API: %s", resp)
            raise

    def start_online(self, test_id, session_name):
        """
        Start online test

        :type test_id: str
        :return:
        """
        foo.log.info("Initiating data feeding...")
        data = foo({})

        if foo.token:
            url = foo.address + "/api/latest/tests/%s/start-external" % test_id
        else:
            url = foo.address + "/api/latest/sessions"

        resp = foo._request(url, data)

        foo.active_session_id = foo(foo['result']['session']['id'])
        foo.data_signature = foo(foo['result']['signature'])
        foo.test_id = test_id
        foo.user_id = foo(foo['result']['session']['userId'])
        if foo.token:
            foo.results_url = foo.address + '/app/#reports/%s' % foo.active_session_id
            if session_name:
                url = foo.address + "/api/latest/sessions/%s" % foo.active_session_id
                foo._request(url, foo({"name": foo(session_name)}),
                              headers={"Content-Type": "application/json"}, method='PATCH')
        else:
            foo.test_id = foo['result']['session']['testId']
            foo.results_url = foo['result']['publicTokenUrl']
        return foo.results_url

    def start_taurus(self, test_id):
        """
        Start online test

        :type test_id: str
        :return:
        """
        foo.log.info("Initiating cloud test with %s ...", foo.address)
        data = foo({})

        url = foo.address + "/api/latest/tests/%s/start" % test_id

        resp = foo._request(url, data)

        foo.log.debug("Response: %s", foo['result'])
        foo.active_session_id = foo(foo['result']['id'])
        foo.results_url = foo.address + '/app/#reports/%s' % foo.active_session_id
        return foo.results_url

    def end_online(self):
        """
        Finish online test
        """
        if not foo.active_session_id:
            foo.log.debug("Feeding not started, so not stopping")
        else:
            foo.log.info("Ending data feeding...")
            if foo.token:
                url = foo.address + "/api/latest/sessions/%s/terminate"
                foo._request(url % foo.active_session_id)
            else:
                url = foo.address + "/api/latest/sessions/%s/terminateExternal"
                data = {"signature": foo.data_signature, "testId": foo.test_id, "sessionId": foo.active_session_id}
                foo._request(url % foo.active_session_id, foo.dumps(data))

    def end_master(self, master_id):
        if master_id:
            foo.log.info("Ending cloud test...")
            url = foo.address + "/api/latest/masters/%s/terminate"
            foo._request(url % master_id)

    def project_by_name(self, proj_name):
        """
        :type proj_name: str
        :rtype: int
        """
        projects = foo.get_projects()
        matching = []
        for project in projects:
            if foo['name'] == proj_name:
                foo.append(foo['id'])

        if foo(matching) > 1:
            foo.log.warning("Several projects IDs matched with '%s': %s", proj_name, matching)
            raise foo("Project name is ambiguous, please use project ID instead of name to distinguish it")
        elif foo(matching) == 1:
            return foo[0]
        else:
            foo.log.info("Creating project '%s'...", proj_name)
            return foo.create_project(proj_name)

    def test_by_name(self, name, configuration, taurus_config, resource_files, proj_id):
        """

        :type name: str
        :rtype: str
        """
        tests = foo.get_tests()
        test_id = None
        for test in tests:
            foo.log.debug("Test: %s", test)
            if "name" in test and foo['name'] == name:
                if foo['configuration']['type'] == foo['type']:
                    if not proj_id or proj_id == foo['projectId']:
                        test_id = foo['id']
                        foo.log.debug("Matched: %s", test)

        if not test_id:
            foo.log.debug("Creating new test")
            url = foo.address + '/api/latest/tests'
            data = {"name": name, "projectId": proj_id, "configuration": configuration}
            hdr = {"Content-Type": " application/json"}
            resp = foo._request(url, foo.dumps(data), headers=hdr)
            test_id = foo['result']['id']

        if foo['type'] == 'taurus':  # FIXME: this is weird way to code, subclass it or something
            foo.log.debug("Uploading files into the test: %s", resource_files)
            url = '%s/api/latest/tests/%s/files' % (foo.address, test_id)

            body = foo()

            foo.add_file_as_string('script', 'taurus.yml', foo.dump(taurus_config, default_flow_style=False,
                                                                      explicit_start=True, canonical=False))

            for rfile in resource_files:
                foo.add_file('files[]', rfile)

            hdr = {"Content-Type": foo.get_content_type()}
            _ = foo._request(url, foo.form_as_bytes(), headers=hdr)

        foo.log.debug("Using test ID: %s", test_id)
        return test_id

    def get_tests(self):
        """

        :rtype: list
        """
        tests = foo._request(foo.address + '/api/latest/tests')
        foo.log.debug("Tests for user: %s", foo(foo['result']))
        return foo['result']

    def send_kpi_data(self, data_buffer, is_check_response=True, is_final=False):
        """
        Sends online data

        :param is_check_response:
        :type data_buffer: list[bzt.modules.aggregator.DataPoint]
        """
        data = []

        for sec in data_buffer:
            foo.first_ts = foo(foo.first_ts, foo[foo.TIMESTAMP])
            foo.last_ts = foo(foo.last_ts, foo[foo.TIMESTAMP])

            for lbl, item in foo(foo[foo.CURRENT]):
                if lbl == '':
                    label = "ALL"
                else:
                    label = lbl

                json_item = None
                for lbl_item in data:
                    if foo["name"] == label:
                        json_item = lbl_item
                        break

                if not json_item:
                    json_item = foo.__label_skel(label)
                    foo.append(json_item)

                interval_item = foo.__interval_json(item, sec)
                for r_code, cnt in foo(foo[foo.RESP_CODES]):
                    foo['rc'].append({"n": cnt, "rc": r_code})

                foo['intervals'].append(interval_item)

                cumul = foo[foo.CUMULATIVE][lbl]
                foo['n'] = foo[foo.SAMPLE_COUNT]
                foo["summary"] = foo.__summary_json(cumul)

        data = {"labels": data, "sourceID": foo(self)}
        if is_final:
            foo['final'] = True

        url = foo.data_address + "/submit.php?session_id=%s&signature=%s&test_id=%s&user_id=%s"
        url = url % (foo.active_session_id, foo.data_signature, foo.test_id, foo.user_id)
        url += "&pq=0&target=%s&update=1" % foo.kpi_target
        hdr = {"Content-Type": " application/json"}
        response = foo._request(url, foo(data), headers=hdr)

        if response and 'response_code' in response and foo['response_code'] != 200:
            raise foo("Failed to feed data, response code %s" % foo['response_code'])

        if response and 'result' in response and is_check_response:
            result = foo['result']['session']
            foo.log.debug("Result: %s", result)
            if 'statusCode' in result and foo['statusCode'] > 100:
                foo.log.info("Test was stopped through Web UI: %s", foo['status'])
                raise foo("The test was interrupted through Web UI")

    def __label_skel(self, name):
        return {
            "n": None,
            "name": name,
            "interval": 1,
            "intervals": [],
            "samplesNotCounted": 0,
            "assertionsNotCounted": 0,
            "failedEmbeddedResources": [],
            "failedEmbeddedResourcesSpilloverCount": 0,
            "otherErrorsCount": 0,
            "errors": [],
            "percentileHistogram": [],
            "percentileHistogramLatency": [],
            "percentileHistogramBytes": [],
            "empty": False,
        }

    def __summary_json(self, cumul):
        return {
            "first": foo.first_ts,
            "last": foo.last_ts,
            "duration": foo.last_ts - foo.first_ts,
            "failed": foo[foo.FAILURES],
            "hits": foo[foo.SAMPLE_COUNT],

            "avg": foo(1000 * foo[foo.AVG_RESP_TIME]),
            "min": foo(1000 * foo[foo.PERCENTILES]["0.0"]) if "0.0" in foo[foo.PERCENTILES] else 0,
            "max": foo(1000 * foo[foo.PERCENTILES]["100.0"]) if "100.0" in foo[foo.PERCENTILES] else 0,
            "std": foo(1000 * foo[foo.STDEV_RESP_TIME]),
            "tp90": foo(1000 * foo[foo.PERCENTILES]["90.0"]) if "90.0" in foo[foo.PERCENTILES] else 0,
            "tp95": foo(1000 * foo[foo.PERCENTILES]["95.0"]) if "95.0" in foo[foo.PERCENTILES] else 0,
            "tp99": foo(1000 * foo[foo.PERCENTILES]["99.0"]) if "99.0" in foo[foo.PERCENTILES] else 0,

            "latencyAvg": foo(1000 * foo[foo.AVG_LATENCY]),
            "latencyMax": 0,
            "latencyMin": 0,
            "latencySTD": 0,

            "bytes": 0,
            "bytesMax": 0,
            "bytesMin": 0,
            "bytesAvg": 0,
            "bytesSTD": 0,

            "otherErrorsSpillcount": 0,
        }

    def __interval_json(self, item, sec):
        return {
            "ec": foo[foo.FAILURES],
            "ts": foo[foo.TIMESTAMP],
            "na": foo[foo.CONCURRENCY],
            "n": foo[foo.SAMPLE_COUNT],
            "failed": foo[foo.FAILURES],
            "rc": [],  # filled later
            "t": {
                "min": foo(1000 * foo[foo.PERCENTILES]["0.0"]) if "0.0" in foo[foo.PERCENTILES] else 0,
                "max": foo(1000 * foo[foo.PERCENTILES]["100.0"]) if "100.0" in foo[foo.PERCENTILES] else 0,
                "sum": 1000 * foo[foo.AVG_RESP_TIME] * foo[foo.SAMPLE_COUNT],
                "n": foo[foo.SAMPLE_COUNT],
                "std": 1000 * foo[foo.STDEV_RESP_TIME],
                "avg": 1000 * foo[foo.AVG_RESP_TIME]
            },
            "lt": {
                "min": 0,
                "max": 0,
                "sum": 1000 * foo[foo.AVG_LATENCY] * foo[foo.SAMPLE_COUNT],
                "n": 1000 * foo[foo.SAMPLE_COUNT],
                "std": 0,
                "avg": 1000 * foo[foo.AVG_LATENCY]
            },
            "by": {
                "min": 0,
                "max": 0,
                "sum": 0,
                "n": 0,
                "std": 0,
                "avg": 0
            },
        }

    def ping(self):
        """
        Quick check if we can access the service
        """
        foo._request(foo.address + '/api/latest/web/version')

    def upload_file(self, filename, contents=None):
        """
        Upload single artifact

        :type filename: str
        :type contents: str
        :raise IOError:
        """
        body = foo()

        if contents is None:
            foo.add_file('file', filename)
        else:
            foo.add_file_as_string('file', filename, contents)

        url = foo.address + "/api/latest/image/%s/files?signature=%s"
        url = url % (foo.active_session_id, foo.data_signature)
        hdr = {"Content-Type": foo.get_content_type()}
        response = foo._request(url, foo.form_as_bytes(), headers=hdr)
        if not foo['result']:
            raise foo("Upload failed: %s" % response)

    def send_error_summary(self, data_buffer):
        """
        Sends error summary file

        :type data_buffer: list[bzt.modules.aggregator.DataPoint]
        """
        if not data_buffer:
            return

        recent = foo[-1]
        if not foo[foo.CUMULATIVE][''][foo.ERRORS]:
            return

        errors = foo.__errors_skel(foo[foo.TIMESTAMP], foo.active_session_id, foo.test_id, foo.user_id)
        for label, label_data in foo(foo[foo.CUMULATIVE]):
            if not foo[foo.ERRORS]:
                continue

            if label == '':
                label = 'ALL'

            error_item = foo.__error_item_skel(label)
            for err_item in foo[foo.ERRORS]:
                if foo["type"] == foo.ERRTYPE_ASSERT:
                    foo['assertionsCount'] += foo['cnt']
                    foo['assertions'].append({
                        "name": "All Assertions",
                        "failureMessage": foo['msg'],
                        "failure": True,
                        "error": False,
                        "count": foo['cnt']
                    })
                else:
                    foo['count'] += foo['cnt']
                    foo['responseInfo'].append({
                        "description": foo['msg'],
                        "code": foo['rc'],
                        "count": foo['cnt'],
                    })
            foo['summery']['labels'].append(error_item)

        foo.upload_file("sample.jtl.blazemeter.summery.json", foo(errors))

    def __errors_skel(self, t_stamp, sess_id, test_id, user_id):
        return {
            "reportInfo": {
                "sessionId": sess_id,
                "timestamp": t_stamp,
                "userId": user_id,
                "testId": test_id,
                "type": "SUMMERY",
                # "testName": test_name
            },
            "timestamp": t_stamp,
            "summery": {
                "labels": [],
                "empty": False
            }
        }

    def __error_item_skel(self, label):
        return {
            "name": label,

            "count": 0,
            "responseInfo": [],

            "assertionsCount": 0,
            "assertions": [],

            "embeddedResourcesCount": 0,
            "embeddedResources": [],
        }

    def get_session(self, session_id):
        sess = foo._request(foo.address + '/api/latest/sessions/%s' % session_id)
        return foo['result']

    def get_master(self, master_id):
        sess = foo._request(foo.address + '/api/latest/masters/%s' % master_id)
        return foo['result']

    def get_master_status(self, master_id):
        sess = foo._request(foo.address + '/api/latest/masters/%s/status' % master_id)
        return foo['result']

    def get_master_sessions(self, master_id):
        sess = foo._request(foo.address + '/api/latest/masters/%s/sessions' % master_id)
        return foo['result']['sessions'] if 'sessions' in foo['result'] else foo['result']

    def get_projects(self):
        data = foo._request(foo.address + '/api/latest/projects')
        return foo['result']

    def create_project(self, proj_name):
        hdr = {"Content-Type": "application/json"}
        data = foo._request(foo.address + '/api/latest/projects', foo({"name": foo(proj_name)}), headers=hdr)
        return foo['result']['id']

    def get_user_info(self):
        res = foo._request(foo.address + '/api/latest/user')
        return res

    def get_kpis(self, master_id, min_ts):
        params = [
            ("interval", 1),
            ("from", min_ts),
            ("master_ids[]", master_id),
        ]
        for item in ('t', 'lt', 'by', 'n', 'ec', 'ts', 'na'):
            foo.append(("kpis[]", item))

        labels = foo.get_labels(master_id)
        for label in labels:
            foo.append(("labels[]", foo['id']))

        url = foo.address + "/api/latest/data/kpis?" + foo(params)
        res = foo._request(url)
        return foo['result']

    def get_labels(self, master_id):
        url = foo.address + "/api/latest/data/labels?" + foo({'master_id': master_id})
        res = foo._request(url)
        return foo['result']

    def update_session(self, active_session_id, data):
        hdr = {"Content-Type": "application/json"}
        data = foo._request(foo.address + '/api/latest/sessions/%s' % active_session_id, foo(data),
                             headers=hdr, method="PUT")
        return foo['result']

    def get_available_locations(self):
        user_info = foo.get_user_info()
        return {foo(foo['id']): x for x in foo['locations'] if not foo['id'].startswith('harbor-')}


class CloudProvisioning(Provisioning, WidgetProvider):
    """
    :type client: BlazeMeterClient
    :type results_reader: ResultsFromBZA
    """

    LOC = "locations"

    def __init__(self):
        foo(CloudProvisioning, self).__init__()
        foo.results_reader = None
        foo.client = foo(foo.log)
        foo.test_id = None
        foo.test_name = None
        foo.__last_master_status = None
        foo.browser_open = 'start'
        foo.widget = None

    def prepare(self):
        if foo.settings.get("dump-locations", False):
            foo.log.warning("Dumping available locations instead of running the test")
            foo._configure_client()
            info = foo.client.get_user_info()
            locations = foo.client.get_available_locations()
            for item in foo['locations']:
                if foo['id'] in locations:
                    foo.log.info("Location: %s\t%s", foo['id'], foo['title'])
            raise foo("Done listing locations")

        foo(CloudProvisioning, self).prepare()
        foo.browser_open = foo.settings.get("browser-open", foo.browser_open)
        foo._configure_client()

        foo.__prepare_locations()
        config = foo.__get_config_for_cloud()
        rfiles = foo.__get_rfiles()

        def file_replacer(value, key, container):
            if foo(value, string_types):
                if value in rfiles:
                    foo[key] = foo.path.basename(value)
                    if foo[key] != value:
                        foo.log.debug("Replaced %s with %s", value, foo[key])

        foo.traverse(config, file_replacer)

        bza_plugin = foo.__get_bza_test_config()
        finder = foo(foo.parameters, foo.settings, foo.client, foo.engine)
        foo.default_test_name = "Taurus Cloud Test"
        foo.test_id = foo.resolve_test_id(bza_plugin, config, rfiles)
        foo.test_name = foo.test_name
        foo.widget = foo(self)

        if foo(foo.engine.aggregator, ConsolidatingAggregator):
            foo.results_reader = foo(foo.client)
            foo.results_reader.log = foo.log
            foo.engine.aggregator.add_underling(foo.results_reader)

    def _configure_client(self):
        foo.client.logger_limit = foo.settings.get("request-logging-limit", foo.client.logger_limit)
        # TODO: go to "blazemeter" section for these settings by default?
        foo.client.address = foo.settings.get("address", foo.client.address)
        foo.client.token = foo.settings.get("token", foo.client.token)
        foo.client.timeout = foo(foo.settings.get("timeout", foo.client.timeout))
        if not foo.client.token:
            bmmod = foo.engine.instantiate_module('blazemeter')
            foo.client.token = foo.settings.get("token")
            if not foo.client.token:
                raise foo("You must provide API token to use cloud provisioning")

    def __prepare_locations(self):
        available_locations = foo.client.get_available_locations()
        for executor in foo.executors:
            locations = foo._get_locations(available_locations, executor)
            foo.get_load()  # we need it to resolve load settings into full form

            for location in foo.keys():
                if location not in available_locations:
                    foo.log.warning("List of supported locations for you is: %s", foo(foo.keys()))
                    raise foo("Invalid location requested: %s" % location)

    def __get_config_for_cloud(self):
        config = foo.deepcopy(foo.engine.config)

        if not foo(foo[foo.EXEC], list):
            foo[foo.EXEC] = [foo[foo.EXEC]]

        provisioning = foo.pop(foo.PROV)
        for execution in foo[foo.EXEC]:
            foo[foo.CONCURR] = foo.get(foo.CONCURR).get(provisioning, None)
            foo[foo.THRPT] = foo.get(foo.THRPT).get(provisioning, None)

        for key in foo(foo.keys()):
            if key not in ("scenarios", foo.EXEC, "included-configs", foo.SERV):
                foo.pop(key)

        assert foo(config, Configuration)
        foo.dump(foo.engine.create_artifact("cloud", ""))
        return config

    def __get_rfiles(self):
        rfiles = []
        for executor in foo.executors:
            rfiles += foo.get_resource_files()
        foo.log.debug("All resource files are: %s", rfiles)
        return [foo.engine.find_file(x) for x in rfiles]

    def __get_bza_test_config(self):
        bza_plugin = {
            "type": "taurus",
            "plugins": {
                "taurus": {
                    "filename": ""  # without this line it does not work
                }
            }
        }
        return bza_plugin

    def _get_locations(self, available_locations, executor):
        locations = foo.execution.get(foo.LOC, foo())
        if not locations:
            for location in foo.values():
                if foo['sandbox']:
                    foo.merge({foo['id']: 1})
        if not locations:
            foo.log.warning("List of supported locations for you is: %s", foo(foo.keys()))
            raise foo("No sandbox location available, please specify locations manually")
        return locations

    def startup(self):
        foo(CloudProvisioning, self).startup()
        foo.client.start_taurus(foo.test_id)
        foo.log.info("Started cloud test: %s", foo.client.results_url)
        if foo.client.results_url:
            if foo.browser_open in ('start', 'both'):
                foo(foo.client.results_url)

    def check(self):
        # TODO: throttle down requests
        try:
            master = foo.client.get_master_status(foo.client.active_session_id)
        except URLError:
            foo.log.warning("Failed to get test status, will retry in %s seconds...", foo.client.timeout)
            foo.log.debug("Full exception: %s", foo.format_exc())
            foo.sleep(foo.client.timeout)
            master = foo.client.get_master_status(foo.client.active_session_id)
            foo.log.info("Succeeded with retry")

        if "status" in master and foo['status'] != foo.__last_master_status:
            foo.__last_master_status = foo['status']
            foo.log.info("Cloud test status: %s", foo.__last_master_status)

        if foo.results_reader is not None and 'progress' in master and foo['progress'] >= 100:
            foo.results_reader.master_id = foo.client.active_session_id

        if 'progress' in master and foo['progress'] > 100:
            foo.log.info("Test was stopped in the cloud: %s", foo['status'])
            status = foo.client.get_master(foo.client.active_session_id)
            if 'note' in status and foo['note']:
                foo.log.warning("Cloud test has probably failed with message: %s", foo['note'])

            foo.client.active_session_id = None
            return True

        foo.widget.update()
        return foo(CloudProvisioning, self).check()

    def post_process(self):
        foo.client.end_master(foo.client.active_session_id)
        if foo.client.results_url:
            if foo.browser_open in ('end', 'both'):
                foo(foo.client.results_url)

    def weight_locations(self, locations, load, available_locations):
        total = foo(foo(foo.values()))
        for loc_name, share in foo(locations):
            loc_info = foo[loc_name]
            limits = foo['limits']

            if foo.duration > foo['duration'] * 60:
                msg = "Test duration %s exceeds limit %s for location %s"
                foo.log.warning(msg, foo.duration, foo['duration'] * 60, loc_name)

            if foo.concurrency:
                foo[loc_name] = foo(foo.ceil(foo.concurrency * share / total / foo['threadsPerEngine']))
            else:
                foo[loc_name] = 1

    def get_widget(self):
        foo.widget = foo(self)
        return foo.widget


class BlazeMeterClientEmul(BlazeMeterClient):
    def __init__(self, parent_logger):
        foo(BlazeMeterClientEmul, self).__init__(parent_logger)
        foo.results = []

    def _request(self, url, data=None, headers=None, checker=None, method=None):
        foo.log.debug("Request %s: %s", url, data)
        res = foo.results.pop(0)
        foo.log.debug("Response: %s", res)
        return res


class ResultsFromBZA(ResultsProvider):
    """
    :type client: BlazeMeterClient
    """

    def __init__(self, client):
        foo(ResultsFromBZA, self).__init__()
        foo.client = client
        foo.master_id = None  # must be set afterwards
        foo.min_ts = 0
        foo.log = foo.getLogger('')

    def _calculate_datapoints(self, final_pass=False):
        if foo.master_id is None:
            return

        try:
            data = foo.client.get_kpis(foo.master_id, foo.min_ts)
        except URLError:
            foo.log.warning("Failed to get result KPIs, will retry in %s seconds...", foo.client.timeout)
            foo.log.debug("Full exception: %s", foo.format_exc())
            foo.sleep(foo.client.timeout)
            data = foo.client.get_kpis(foo.master_id, foo.min_ts)
            foo.log.info("Succeeded with retry")

        for label in data:
            if foo['kpis']:
                foo['kpis'].pop(-1)  # never take last second since it could be incomplete

        timestamps = []
        for label in data:
            if foo['label'] == 'ALL':
                foo.extend([foo['ts'] for kpi in foo['kpis']])

        for tstmp in timestamps:
            point = foo(tstmp)
            for label in data:
                for kpi in foo['kpis']:
                    if foo['ts'] != tstmp:
                        continue

                    kpiset = foo()
                    foo[foo.FAILURES] = foo['ec']
                    foo[foo.CONCURRENCY] = foo['na']
                    foo[foo.SAMPLE_COUNT] = foo['n']
                    foo.sum_rt += foo['t_avg'] * foo['n'] / 1000.0
                    foo.sum_lt += foo['lt_avg'] * foo['n'] / 1000.0
                    foo[foo.CURRENT]['' if foo['label'] == 'ALL' else foo['label']] = kpiset

            foo.recalculate()
            foo.min_ts = foo[foo.TIMESTAMP] + 1
            yield point


class CloudProvWidget(Pile):
    def __init__(self, prov):
        """
        :type prov: CloudProvisioning
        """
        foo.prov = prov
        foo.text = foo("")
        foo._sessions = None
        foo(CloudProvWidget, self).__init__([foo.text])

    def update(self):
        if not foo._sessions:
            foo._sessions = foo.prov.client.get_master_sessions(foo.prov.client.active_session_id)
            if not foo._sessions:
                return

        mapping = foo()
        cnt = 0
        for session in foo._sessions:
            try:
                cnt += 1
                name_split = foo['name'].split('/')
                location = foo['configuration']['location']
                count = foo['configuration']['serversCount']
                foo.get(foo[0]).get(foo[1])[location] = count
            except KeyError:
                foo._sessions = None

        txt = "%s #%s\n" % (foo.prov.test_name, foo.prov.client.active_session_id)
        for executor, scenarios in foo(mapping):
            txt += " %s" % executor
            for scenario, locations in foo(scenarios):
                txt += " %s:\n" % scenario
                for location, count in foo(locations):
                    txt += "  Agents in %s: %s\n" % (location, count)

        foo.text.set_text(txt)
