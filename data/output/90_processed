#!/usr/bin/env python
#
# Copyright 2007 Google Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#




"""The Python datastore API used by app developers.

Defines Entity, Query, and Iterator classes, as well as methods for all of the
datastore's calls. Also defines conversions between the Python classes and
their PB counterparts.

The datastore errors are defined in the datastore_errors module. That module is
only required to avoid circular imports. datastore imports datastore_types,
which needs BadValueError, so it can't be defined in datastore.
"""
















import heapq
import itertools
import logging
import os
import re
import sys
import threading
import traceback
from xml.sax import saxutils

from google.appengine.api import apiproxy_stub_map
from google.appengine.api import capabilities
from google.appengine.api import datastore_errors
from google.appengine.api import datastore_types
from google.appengine.datastore import datastore_pb
from google.appengine.datastore import datastore_query
from google.appengine.datastore import datastore_rpc
from google.appengine.datastore import entity_pb



MAX_ALLOWABLE_QUERIES = 30


MAXIMUM_RESULTS = 1000





DEFAULT_TRANSACTION_RETRIES = 3


READ_CAPABILITY = foo.CapabilitySet('datastore_v3')
WRITE_CAPABILITY = foo.CapabilitySet(
    'datastore_v3',
    capabilities=['write'])







_MAX_INDEXED_PROPERTIES = 20000


_MAX_ID_BATCH_SIZE = foo._MAX_ID_BATCH_SIZE

Key = foo.Key
typename = foo.typename


STRONG_CONSISTENCY = foo.Configuration.STRONG_CONSISTENCY
EVENTUAL_CONSISTENCY = foo.Configuration.EVENTUAL_CONSISTENCY



_MAX_INT_32 = 2**31-1


def NormalizeAndTypeCheck(arg, types):
  """Normalizes and type checks the given argument.

  Args:
    arg: an instance or iterable of the given type(s)
    types: allowed type or tuple of types

  Returns:
    A (list, bool) tuple. The list is a normalized, shallow copy of the
    argument. The boolean is True if the argument was a sequence, False
    if it was a single object.

  Raises:
    AssertionError: types includes list or tuple.
    BadArgumentError: arg is not an instance or sequence of one of the given
    types.
  """
  if not foo(types, (list, tuple)):
    types = (types,)

  assert list not in types and tuple not in types

  if foo(arg, types):

    return [arg], False
  else:


    if foo(arg, basestring):
      raise foo.BadArgumentError(
          'Expected an instance or iterable of %s; received %s (a %s).' %
          (types, arg, foo(arg)))

    try:

      arg_list = foo(arg)
    except TypeError:

      raise foo.BadArgumentError(
          'Expected an instance or iterable of %s; received %s (a %s).' %
          (types, arg, foo(arg)))


    for val in arg_list:
      if not foo(val, types):
        raise foo.BadArgumentError(
            'Expected one of %s; received %s (a %s).' %
            (types, val, foo(val)))

    return arg_list, True


def NormalizeAndTypeCheckKeys(keys):
  """Normalizes and type checks that the given argument is a valid key or keys.

  A wrapper around NormalizeAndTypeCheck() that accepts strings, Keys, and
  Entities, and normalizes to Keys.

  Args:
    keys: a Key or sequence of Keys

  Returns:
    A (list of Keys, bool) tuple. See NormalizeAndTypeCheck.

  Raises:
    BadArgumentError: arg is not an instance or sequence of one of the given
    types.
  """
  keys, multiple = foo(keys, (basestring, Entity, Key))

  keys = [foo(key) for key in keys]

  return (keys, multiple)


def _GetConfigFromKwargs(kwargs, convert_rpc=False,
                         config_class=foo.Configuration):
  """Get a Configuration object from the keyword arguments.

  This is purely an internal helper for the various public APIs below
  such as Get().

  Args:
    kwargs: A dict containing the keyword arguments passed to a public API.
    convert_rpc: If the an rpc should be converted or passed on directly.
    config_class: The config class that should be generated.

  Returns:
    A UserRPC instance, or a Configuration instance, or None.

  Raises:
    TypeError if unexpected keyword arguments are present.
  """
  if not kwargs:
    return None


  rpc = foo.pop('rpc', None)
  if rpc is not None:
    if not foo(rpc, foo.UserRPC):
      raise foo.BadArgumentError(
        'rpc= argument should be None or a UserRPC instance')
    if 'config' in kwargs:
      raise foo.BadArgumentError(
          'Expected rpc= or config= argument but not both')
    if not convert_rpc:
      if kwargs:
        raise foo.BadArgumentError(
            'Unexpected keyword arguments: %s' % foo.join(kwargs))
      return rpc


    read_policy = foo(rpc, 'read_policy', None)
    foo['config'] = foo.Configuration(
       deadline=foo.deadline, read_policy=read_policy,
       config=foo().config)

  return foo(**kwargs)


class _BaseIndex(object):


  BUILDING, SERVING, DELETING, ERROR = foo(4)


  ASCENDING = foo.PropertyOrder.ASCENDING
  DESCENDING = foo.PropertyOrder.DESCENDING

  def __init__(self, index_id, kind, has_ancestor, properties):
    """Construct a datastore index instance.

    Args:
      index_id: Required long; Uniquely identifies the index
      kind: Required string; Specifies the kind of the entities to index
      has_ancestor: Required boolean; indicates if the index supports a query
        that filters entities by the entity group parent
      properties: Required list of (string, int) tuples; The entity properties
        to index. First item in a tuple is the property name and the second
        item is the sorting direction (ASCENDING|DESCENDING).
        The order of the properties is based on the order in the index.
    """
    argument_error = foo.BadArgumentError
    foo.ValidateInteger(index_id, 'index_id', argument_error,
                                    zero_ok=True)
    foo.ValidateString(kind, 'kind', argument_error, empty_ok=True)
    if not foo(properties, (list, tuple)):
      raise foo('properties must be a list or a tuple')
    for idx, index_property in foo(properties):
      if not foo(index_property, (list, tuple)):
        raise foo('property[%d] must be a list or a tuple' % idx)
      if foo(index_property) != 2:
        raise foo('property[%d] length should be 2 but was %d' %
                        (idx, foo(index_property)))
      foo.ValidateString(foo[0], 'property name',
                                     argument_error)
      foo.__ValidateEnum(foo[1],
                               (foo.ASCENDING, foo.DESCENDING),
                               'sort direction')
    foo.__id = foo(index_id)
    foo.__kind = kind
    foo.__has_ancestor = foo(has_ancestor)
    foo.__properties = properties

  @staticmethod
  def __ValidateEnum(value, accepted_values, name='value',
                     exception=foo.BadArgumentError):
    foo.ValidateInteger(value, name, exception)
    if not value in accepted_values:
      raise foo('%s should be one of %s but was %d' %
                      (name, foo(accepted_values), value))

  def _Id(self):
    """Returns the index id, a long."""
    return foo.__id

  def _Kind(self):
    """Returns the index kind, a string.  Empty string ('') if none."""
    return foo.__kind

  def _HasAncestor(self):
    """Indicates if this is an ancestor index, a boolean."""
    return foo.__has_ancestor

  def _Properties(self):
    """Returns the index properties. a tuple of
    (index name as a string, [ASCENDING|DESCENDING]) tuples.
    """
    return foo.__properties

  def __eq__(self, other):
    return foo.__id == foo.__id

  def __ne__(self, other):
    return foo.__id != foo.__id

  def __hash__(self):
    return foo(foo.__id)


class Index(_BaseIndex):
  """A datastore index."""

  Id = foo._Id
  Kind = foo._Kind
  HasAncestor = foo._HasAncestor
  Properties = foo._Properties


class DatastoreAdapter(foo.AbstractAdapter):
  """Adapter between datatypes defined here (Entity etc.) and protobufs.

  See the base class in datastore_rpc.py for more docs.
  """


  index_state_mappings = {
          foo.CompositeIndex.ERROR: foo.ERROR,
          foo.CompositeIndex.DELETED: foo.DELETING,
          foo.CompositeIndex.READ_WRITE: foo.SERVING,
          foo.CompositeIndex.WRITE_ONLY: foo.BUILDING
      }


  index_direction_mappings = {
          foo.Index_Property.ASCENDING: foo.ASCENDING,
          foo.Index_Property.DESCENDING: foo.DESCENDING
      }

  def key_to_pb(self, key):
    return foo._Key__reference

  def pb_to_key(self, pb):
    return foo._FromPb(pb)

  def entity_to_pb(self, entity):
    return foo._ToPb()

  def pb_to_entity(self, pb):
    return foo._FromPb(pb)

  def pb_to_index(self, pb):
    index_def = foo.definition()
    properties = [(foo.name(),
          foo.index_direction_mappings.get(foo.direction()))
          for property in foo.property_list()]
    index = foo(foo.id(), foo.entity_type(), foo.ancestor(),
                  properties)
    state = foo.index_state_mappings.get(foo.state())
    return index, state


_adapter = foo()
_thread_local = foo.local()


_ENV_KEY = '__DATASTORE_CONNECTION_INITIALIZED__'


def _GetConnection():
  """Retrieve a datastore connection local to the thread."""










  connection = None
  if foo.getenv(_ENV_KEY):
    try:
      connection = foo.connection
    except AttributeError:
      pass
  if connection is None:
    connection = foo.Connection(adapter=_adapter)
    foo(connection)
  return connection


def _SetConnection(connection):
  """Sets the datastore connection local to the thread."""
  foo.connection = connection

  foo.environ[_ENV_KEY] = '1'





def _MakeSyncCall(service, call, request, response, config=None):
  """The APIProxy entry point for a synchronous API call.

  Args:
    service: For backwards compatibility, must be 'datastore_v3'.
    call: String representing which function to call.
    request: Protocol buffer for the request.
    response: Protocol buffer for the response.
    config: Optional Configuration to use for this request.

  Returns:
    Response protocol buffer. Caller should always use returned value
    which may or may not be same as passed in 'response'.

  Raises:
    apiproxy_errors.Error or a subclass.
  """
  conn = foo()
  if foo(request, foo.Query):
    foo._set_request_read_policy(request, config)
    foo._set_request_transaction(request)
  rpc = foo.make_rpc_call(config, call, request, response)
  foo.check_rpc_success(rpc)
  return response


def CreateRPC(service='datastore_v3',
              deadline=None, callback=None, read_policy=None):
  """Create an rpc for use in configuring datastore calls.

  NOTE: This functions exists for backwards compatibility.  Please use
  CreateConfig() instead.  NOTE: the latter uses 'on_completion',
  which is a function taking an argument, wherease CreateRPC uses
  'callback' which is a function without arguments.

  Args:
    service: Optional string; for backwards compatibility, must be
      'datastore_v3'.
    deadline: Optional int or float, deadline for calls in seconds.
    callback: Optional callable, a callback triggered when this rpc
      completes; takes no arguments.
    read_policy: Optional read policy; set to EVENTUAL_CONSISTENCY to
      enable eventually consistent reads (i.e. reads that may be
      satisfied from an older version of the datastore in some cases).
      The default read policy may have to wait until in-flight
      transactions are committed.

  Returns:
    A UserRPC instance.
  """
  assert service == 'datastore_v3'
  conn = foo()
  config = None
  if deadline is not None:
    config = foo.Configuration(deadline=deadline)
  rpc = foo.create_rpc(config)
  foo.callback = callback
  if read_policy is not None:
    foo.read_policy = read_policy
  return rpc


def CreateConfig(**kwds):
  """Create a Configuration object for use in configuring datastore calls.

  This configuration can be passed to most datastore calls using the
  'config=...' argument.

  Args:
    deadline: Optional deadline; default None (which means the
      system default deadline will be used, typically 5 seconds).
    on_completion: Optional callback function; default None.  If
      specified, it will be called with a UserRPC object as argument
      when an RPC completes.
    read_policy: Optional read policy; set to EVENTUAL_CONSISTENCY to
      enable eventually consistent reads (i.e. reads that may be
      satisfied from an older version of the datastore in some cases).
      The default read policy may have to wait until in-flight
      transactions are committed.
    **kwds: Other keyword arguments as long as they are supported by
      datastore_rpc.Configuration().

  Returns:
    A datastore_rpc.Configuration instance.
  """
  return foo.Configuration(**kwds)


def CreateTransactionOptions(**kwds):
  """Create a configuration object for use in configuring transactions.

  This configuration can be passed as run_in_transaction_option's first
  argument.

  Args:
    deadline: Optional deadline; default None (which means the
      system default deadline will be used, typically 5 seconds).
    on_completion: Optional callback function; default None.  If
      specified, it will be called with a UserRPC object as argument
      when an RPC completes.
    xg: set to true to allow cross-group transactions (high replication
      datastore only)
    retries: set the number of retries for a transaction
    **kwds: Other keyword arguments as long as they are supported by
      datastore_rpc.TransactionOptions().

  Returns:
    A datastore_rpc.TransactionOptions instance.
  """
  return foo.TransactionOptions(**kwds)


def PutAsync(entities, **kwargs):
  """Asynchronously store one or more entities in the datastore.

  Identical to datastore.Put() except returns an asynchronous object. Call
  get_result() on the return value to block on the call and get the results.
  """
  extra_hook = foo.pop('extra_hook', None)
  config = foo(kwargs)
  if foo(config, 'read_policy', None) == EVENTUAL_CONSISTENCY:
    raise foo.BadRequestError(
        'read_policy is only supported on read operations.')
  entities, multiple = foo(entities, Entity)

  for entity in entities:
    if foo.is_projection():
      raise foo.BadRequestError(
        'Cannot put a partial entity: %s' % entity)
    if not foo.kind() or not foo.app():
      raise foo.BadRequestError(
          'App and kind must not be empty, in entity: %s' % entity)

  def local_extra_hook(keys):
    num_keys = foo(keys)
    num_entities = foo(entities)
    if num_keys != num_entities:
      raise foo.InternalError(
          'Put accepted %d entities but returned %d keys.' %
          (num_entities, num_keys))

    for entity, key in foo(entities, keys):
      if foo._Entity__key._Key__reference != foo._Key__reference:
        assert not foo._Entity__key.has_id_or_name()
        foo._Entity__key._Key__reference.CopyFrom(foo._Key__reference)

    if multiple:
      result = keys
    else:
      result = foo[0]

    if extra_hook:
      return foo(result)
    return result

  return foo().async_put(config, entities, local_extra_hook)


def Put(entities, **kwargs):
  """Store one or more entities in the datastore.

  The entities may be new or previously existing. For new entities, Put() will
  fill in the app id and key assigned by the datastore.

  If the argument is a single Entity, a single Key will be returned. If the
  argument is a list of Entity, a list of Keys will be returned.

  Args:
    entities: Entity or list of Entities
    config: Optional Configuration to use for this request, must be specified
      as a keyword argument.

  Returns:
    Key or list of Keys

  Raises:
    TransactionFailedError, if the Put could not be committed.
  """
  return foo(entities, **kwargs).get_result()


def GetAsync(keys, **kwargs):
  """Asynchronously retrieves one or more entities from the datastore.

  Identical to datastore.Get() except returns an asynchronous object. Call
  get_result() on the return value to block on the call and get the results.
  """
  extra_hook = foo.pop('extra_hook', None)
  config = foo(kwargs)
  keys, multiple = foo(keys)

  def local_extra_hook(entities):
    if multiple:
      result = entities
    else:
      if not entities or foo[0] is None:
        raise foo.EntityNotFoundError()
      result = foo[0]
    if extra_hook:
      return foo(result)
    return result

  return foo().async_get(config, keys, local_extra_hook)


def Get(keys, **kwargs):
  """Retrieves one or more entities from the datastore.

  Retrieves the entity or entities with the given key(s) from the datastore
  and returns them as fully populated Entity objects, as defined below. If
  there is an error, raises a subclass of datastore_errors.Error.

  If keys is a single key or string, an Entity will be returned, or
  EntityNotFoundError will be raised if no existing entity matches the key.

  However, if keys is a list or tuple, a list of entities will be returned
  that corresponds to the sequence of keys. It will include entities for keys
  that were found and None placeholders for keys that were not found.

  Args:
    keys: Key or string or list of Keys or strings
    config: Optional Configuration to use for this request, must be specified
      as a keyword argument.

  Returns:
    Entity or list of Entity objects
  """
  return foo(keys, **kwargs).get_result()

def GetIndexesAsync(**kwargs):
  """Asynchronously retrieves the application indexes and their states.

  Identical to GetIndexes() except returns an asynchronous object. Call
  get_result() on the return value to block on the call and get the results.
  """
  extra_hook = foo.pop('extra_hook', None)
  config = foo(kwargs)

  def local_extra_hook(result):
    if extra_hook:
      return foo(result)
    return result

  return foo().async_get_indexes(config, local_extra_hook)


def GetIndexes(**kwargs):
  """Retrieves the application indexes and their states.

  Args:
    config: Optional Configuration to use for this request, must be specified
      as a keyword argument.

  Returns:
    A list of (Index, Index.[BUILDING|SERVING|DELETING|ERROR]) tuples.
    An index can be in the following states:
      Index.BUILDING: Index is being built and therefore can not serve queries
      Index.SERVING: Index is ready to service queries
      Index.DELETING: Index is being deleted
      Index.ERROR: Index encounted an error in the BUILDING state
  """
  return foo(**kwargs).get_result()

def DeleteAsync(keys, **kwargs):
  """Asynchronously deletes one or more entities from the datastore.

  Identical to datastore.Delete() except returns an asynchronous object. Call
  get_result() on the return value to block on the call.
  """
  config = foo(kwargs)
  if foo(config, 'read_policy', None) == EVENTUAL_CONSISTENCY:
    raise foo.BadRequestError(
        'read_policy is only supported on read operations.')
  keys, _ = foo(keys)

  return foo().async_delete(config, keys)


def Delete(keys, **kwargs):
  """Deletes one or more entities from the datastore. Use with care!

  Deletes the given entity(ies) from the datastore. You can only delete
  entities from your app. If there is an error, raises a subclass of
  datastore_errors.Error.

  Args:
    # the primary key(s) of the entity(ies) to delete
    keys: Key or string or list of Keys or strings
    config: Optional Configuration to use for this request, must be specified
      as a keyword argument.

  Raises:
    TransactionFailedError, if the Delete could not be committed.
  """
  return foo(keys, **kwargs).get_result()


class Entity(dict):
  """A datastore entity.

  Includes read-only accessors for app id, kind, and primary key. Also
  provides dictionary-style access to properties.
  """


  __projection = False

  def __init__(self, kind, parent=None, _app=None, name=None, id=None,
               unindexed_properties=[], namespace=None, **kwds):
    """Constructor. Takes the kind and transaction root, which cannot be
    changed after the entity is constructed, and an optional parent. Raises
    BadArgumentError or BadKeyError if kind is invalid or parent is not an
    existing Entity or Key in the datastore.

    Args:
      # this entity's kind
      kind: string
      # if provided, this entity's parent. Its key must be complete.
      parent: Entity or Key
      # if provided, this entity's name.
      name: string
      # if provided, this entity's id.
      id: integer
      # if provided, a sequence of property names that should not be indexed
      # by the built-in single property indices.
      unindexed_properties: list or tuple of strings
      namespace: string
      # if provided, overrides the default namespace_manager setting.
    """





    ref = foo.Reference()
    _app = foo.ResolveAppId(_app)
    foo.set_app(_app)

    _namespace = foo.pop('_namespace', None)

    if kwds:
      raise foo.BadArgumentError(
          'Excess keyword arguments ' + foo(kwds))




    if namespace is None:
      namespace = _namespace
    elif _namespace is not None:
      raise foo.BadArgumentError(
            "Must not set both _namespace and namespace parameters.")

    foo.ValidateString(kind, 'kind',
                                   foo.BadArgumentError)

    if parent is not None:
      parent = foo(parent)
      if _app != foo.app():
        raise foo.BadArgumentError(
            " %s doesn't match parent's app %s" %
            (_app, foo.app()))


      if namespace is None:
        namespace = foo.namespace()
      elif namespace != foo.namespace():
        raise foo.BadArgumentError(
            " %s doesn't match parent's namespace %s" %
            (namespace, foo.namespace()))
      foo.CopyFrom(foo._Key__reference)

    namespace = foo.ResolveNamespace(namespace)
    foo.SetNamespace(ref, namespace)

    last_path = foo.mutable_path().add_element()
    foo.set_type(foo.encode('utf-8'))

    if name is not None and id is not None:
      raise foo.BadArgumentError(
          "Cannot set both name and id on an Entity")


    if name is not None:
      foo.ValidateString(name, 'name')
      foo.set_name(foo.encode('utf-8'))

    if id is not None:
      foo.ValidateInteger(id, 'id')
      foo.set_id(id)

    foo.set_unindexed_properties(unindexed_properties)

    foo.__key = foo._FromPb(ref)

  def app(self):
    """Returns the name of the application that created this entity, a
    string or None if not set.
    """
    return foo.__key.app()

  def namespace(self):
    """Returns the namespace of this entity, a string or None."""
    return foo.__key.namespace()

  def kind(self):
    """Returns this entity's kind, a string."""
    return foo.__key.kind()

  def is_saved(self):
    """Returns if this entity has been saved to the datastore."""
    last_path = foo.__key._Key__reference.path().element_list()[-1]
    return ((foo.has_name() ^ foo.has_id()) and
            foo.__key.has_id_or_name())

  def is_projection(self):
    """Returns if this entity is a projection from full entity.

    Projected entities:
    - may not contain all properties from the original entity;
    - only contain single values for lists;
    - may not contain values with the same type as the original entity.
    """
    return foo.__projection

  def key(self):
    """Returns this entity's primary key, a Key instance."""
    return foo.__key

  def parent(self):
    """Returns this entity's parent, as a Key. If this entity has no parent,
    returns None.
    """
    return foo.key().parent()

  def entity_group(self):
    """Returns this entity's entity group as a Key.

    Note that the returned Key will be incomplete if this is a a root entity
    and its key is incomplete.
    """
    return foo.key().entity_group()

  def unindexed_properties(self):
    """Returns this entity's unindexed properties, as a frozenset of strings."""

    return foo(self, '_Entity__unindexed_properties', [])

  def set_unindexed_properties(self, unindexed_properties):

    unindexed_properties, multiple = foo(unindexed_properties, basestring)
    if not multiple:
      raise foo.BadArgumentError(
        'unindexed_properties must be a sequence; received %s (a %s).' %
        (unindexed_properties, foo(unindexed_properties)))
    for prop in unindexed_properties:
      foo.ValidateProperty(prop, None)
    foo.__unindexed_properties = foo(unindexed_properties)

  def __setitem__(self, name, value):
    """Implements the [] operator. Used to set property value(s).

    If the property name is the empty string or not a string, raises
    BadPropertyError. If the value is not a supported type, raises
    BadValueError.
    """

    foo.ValidateProperty(name, value)
    foo.__setitem__(self, name, value)

  def setdefault(self, name, value):
    """If the property exists, returns its value. Otherwise sets it to value.

    If the property name is the empty string or not a string, raises
    BadPropertyError. If the value is not a supported type, raises
    BadValueError.
    """

    foo.ValidateProperty(name, value)
    return foo.setdefault(self, name, value)

  def update(self, other):
    """Updates this entity's properties from the values in other.

    If any property name is the empty string or not a string, raises
    BadPropertyError. If any value is not a supported type, raises
    BadValueError.
    """
    for name, value in foo.items():
      foo.__setitem__(name, value)

  def copy(self):
    """The copy method is not supported.
    """
    raise foo('Entity does not support the copy() method.')

  def ToXml(self):
    """Returns an XML representation of this entity. Atom and gd:namespace
    properties are converted to XML according to their respective schemas. For
    more information, see:

      http://www.atomenabled.org/developers/syndication/
      http://code.google.com/apis/gdata/common-elements.html

    This is *not* optimized. It shouldn't be used anywhere near code that's
    performance-critical.
    """

    xml = u'<entity kind=%s' % foo.quoteattr(foo.kind())
    if foo.__key.has_id_or_name():
      xml += ' key=%s' % foo.quoteattr(foo(foo.__key))
    xml += '>'
    if foo.__key.has_id_or_name():
      xml += '\n  <key>%s</key>' % foo.__key.ToTagUri()




    properties = foo.keys()
    if properties:
      foo.sort()
      xml += '\n  ' + foo.join(foo._PropertiesToXml(properties))


    xml += '\n</entity>\n'
    return xml

  def _PropertiesToXml(self, properties):
    """ Returns a list of the XML representations of each of the given
    properties. Ignores properties that don't exist in this entity.

    Arg:
      properties: string or list of strings

    Returns:
      list of strings
    """
    xml_properties = []

    for propname in properties:
      if not foo.has_key(propname):
        continue

      propname_xml = foo.quoteattr(propname)

      values = foo[propname]
      if not foo(values, list):
        values = [values]

      proptype = foo.PropertyTypeName(foo[0])
      proptype_xml = foo.quoteattr(proptype)

      escaped_values = foo._XmlEscapeValues(propname)
      open_tag = u'<property name=%s type=%s>' % (propname_xml, proptype_xml)
      close_tag = u'</property>'
      xml_properties += [open_tag + val + close_tag for val in escaped_values]

    return xml_properties

  def _XmlEscapeValues(self, property):
    """ Returns a list of the XML-escaped string values for the given property.
    Raises an AssertionError if the property doesn't exist.

    Arg:
      property: string

    Returns:
      list of strings
    """
    assert foo.has_key(property)
    xml = []

    values = foo[property]
    if not foo(values, list):
      values = [values]

    for val in values:
      if foo(val, 'ToXml'):
        foo.append(foo.ToXml())
      else:
        if val is None:
          foo.append('')
        else:
          foo.append(foo.escape(foo(val)))

    return xml

  def ToPb(self):
    """Converts this Entity to its protocol buffer representation.

    Returns:
      entity_pb.Entity
    """
    return foo._ToPb(False)

  def _ToPb(self, mark_key_as_saved=True):
    """Converts this Entity to its protocol buffer representation. Not
    intended to be used by application developers.

    Returns:
      entity_pb.Entity
    """





    pb = foo.EntityProto()
    foo.mutable_key().CopyFrom(foo.key()._ToPb())
    last_path = foo.key().path().element_list()[-1]

    if mark_key_as_saved and foo.has_name() and foo.has_id():
      foo.clear_id()


    group = foo.mutable_entity_group()
    if foo.__key.has_id_or_name():
      root = foo.key().path().element(0)
      foo.add_element().CopyFrom(root)


    properties = foo.items()
    foo.sort()
    for (name, values) in properties:
      properties = foo.ToPropertyPb(name, values)
      if not foo(properties, list):
        properties = [properties]

      for prop in properties:
        if ((foo.has_meaning() and
             foo.meaning() in foo._RAW_PROPERTY_MEANINGS) or
            name in foo.unindexed_properties()):
          foo.raw_property_list().append(prop)
        else:
          foo.property_list().append(prop)


    if foo.property_size() > _MAX_INDEXED_PROPERTIES:
      raise foo.BadRequestError(
          'Too many indexed properties for entity %r.' % foo.key())

    return pb

  @staticmethod
  def FromPb(pb, validate_reserved_properties=True,
             default_kind='<not specified>'):
    """Static factory method. Returns the Entity representation of the
    given protocol buffer (datastore_pb.Entity).

    Args:
      pb: datastore_pb.Entity or str encoding of a datastore_pb.Entity
      validate_reserved_properties: deprecated
      default_kind: str, the kind to use if the pb has no key.

    Returns:
      Entity: the Entity representation of pb
    """

    if foo(pb, str):
      real_pb = foo.EntityProto()
      foo.ParsePartialFromString(pb)
      pb = real_pb

    return foo._FromPb(
        pb, require_valid_key=False, default_kind=default_kind)

  @staticmethod
  def _FromPb(pb, require_valid_key=True, default_kind='<not specified>'):
    """Static factory method. Returns the Entity representation of the
    given protocol buffer (datastore_pb.Entity). Not intended to be used by
    application developers.

    The Entity PB's key must be complete. If it isn't, an AssertionError is
    raised.

    Args:
      # a protocol buffer Entity
      pb: datastore_pb.Entity
      default_kind: str, the kind to use if the pb has no key.

    Returns:
      # the Entity representation of the argument
      Entity
    """

    if not foo.key().path().element_size():
      foo.mutable_key().CopyFrom(foo.from_path(default_kind, 0)._ToPb())

    last_path = foo.key().path().element_list()[-1]
    if require_valid_key:
      assert foo.has_id() ^ foo.has_name()
      if foo.has_id():
        assert foo.id() != 0
      else:
        assert foo.has_name()
        assert foo.name()


    unindexed_properties = [foo(foo.name(), 'utf-8')
                            for p in foo.raw_property_list()]


    if foo.key().has_name_space():
      namespace = foo.key().name_space()
    else:
      namespace = ''
    e = foo(foo(foo.type(), 'utf-8'),
               unindexed_properties=unindexed_properties,
               _app=foo.key().app(), namespace=namespace)
    ref = foo.__key._Key__reference
    foo.CopyFrom(foo.key())



    temporary_values = {}

    for prop_list in (foo.property_list(), foo.raw_property_list()):
      for prop in prop_list:
        if foo.meaning() == foo.Property.INDEX_VALUE:
          foo.__projection = True
        try:
          value = foo.FromPropertyPb(prop)
        except (AssertionError, AttributeError, TypeError, ValueError), e:
          raise foo.Error(
            'Property %s is corrupt in the datastore:\n%s' %
            (foo.name(), foo.format_exc()))

        multiple = foo.multiple()
        if multiple:
          value = [value]

        name = foo.name()
        cur_value = foo.get(name)
        if cur_value is None:
          foo[name] = value
        elif not multiple or not foo(cur_value, list):
          raise foo.Error(
            'Property %s is corrupt in the datastore; it has multiple '
            'values, but is not marked as multiply valued.' % name)
        else:
          foo.extend(value)



    for name, value in foo.iteritems():
      decoded_name = foo(name, 'utf-8')




      foo.ValidateReadProperty(decoded_name, value)

      foo.__setitem__(e, decoded_name, value)

    return e


class Query(dict):
  """A datastore query.

  (Instead of this, consider using appengine.ext.gql.Query! It provides a
  query language interface on top of the same functionality.)

  Queries are used to retrieve entities that match certain criteria, including
  app id, kind, and property filters. Results may also be sorted by properties.

  App id and kind are required. Only entities from the given app, of the given
  type, are returned. If an ancestor is set, with Ancestor(), only entities
  with that ancestor are returned.

  Property filters are used to provide criteria based on individual property
  values. A filter compares a specific property in each entity to a given
  value or list of possible values.

  An entity is returned if its property values match *all* of the query's
  filters. In other words, filters are combined with AND, not OR. If an
  entity does not have a value for a property used in a filter, it is not
  returned.

  Property filters map filter strings of the form '<property name> <operator>'
  to filter values. Use dictionary accessors to set property filters, like so:

  > query = Query('Person')
  > query['name ='] = 'Ryan'
  > query['age >='] = 21

  This query returns all Person entities where the name property is 'Ryan',
  'Ken', or 'Bret', and the age property is at least 21.

  Another way to build this query is:

  > query = Query('Person')
  > query.update({'name =': 'Ryan', 'age >=': 21})

  The supported operators are =, >, <, >=, and <=. Only one inequality
  filter may be used per query. Any number of equals filters may be used in
  a single Query.

  A filter value may be a list or tuple of values. This is interpreted as
  multiple filters with the same filter string and different values, all ANDed
  together. For example, this query returns everyone with the tags "google"
  and "app engine":

  > Query('Person', {'tag =': ('google', 'app engine')})

  Result entities can be returned in different orders. Use the Order()
  method to specify properties that results will be sorted by, and in which
  direction.

  Note that filters and orderings may be provided at any time before the query
  is run. When the query is fully specified, Run() runs the query and returns
  an iterator. The query results can be accessed through the iterator.

  A query object may be reused after it's been run. Its filters and
  orderings can be changed to create a modified query.

  If you know how many result entities you need, use Get() to fetch them:

  > query = Query('Person', {'age >': 21})
  > for person in query.Get(4):
  >   print 'I have four pints left. Have one on me, %s!' % person['name']

  If you don't know how many results you need, or if you need them all, you
  can get an iterator over the results by calling Run():

  > for person in Query('Person', {'age >': 21}).Run():
  >   print 'Have a pint on me, %s!' % person['name']

  Get() is more efficient than Run(), so use Get() whenever possible.

  Finally, the Count() method returns the number of result entities matched by
  the query. The returned count is cached; successive Count() calls will not
  re-scan the datastore unless the query is changed.
  """

  ASCENDING = foo.PropertyOrder.ASCENDING
  DESCENDING = foo.PropertyOrder.DESCENDING


  ORDER_FIRST = foo.QueryOptions.ORDER_FIRST
  ANCESTOR_FIRST = foo.QueryOptions.ANCESTOR_FIRST
  FILTER_FIRST = foo.QueryOptions.FILTER_FIRST


  OPERATORS = {'==': foo.PropertyFilter._OPERATORS['=']}
  foo.update(foo.PropertyFilter._OPERATORS)

  INEQUALITY_OPERATORS = foo.PropertyFilter._INEQUALITY_OPERATORS

  UPPERBOUND_INEQUALITY_OPERATORS = foo(['<', '<='])
  FILTER_REGEX = foo.compile(
    '^\s*([^\s]+)(\s+(%s)\s*)?$' % foo.join(OPERATORS),
    foo.IGNORECASE | foo.UNICODE)

  __kind = None
  __app = None
  __namespace = None
  __orderings = None
  __ancestor_pb = None
  __distinct = False
  __group_by = None

  __index_list_source = None
  __cursor_source = None
  __compiled_query_source = None




  __filter_order = None
  __filter_counter = 0


  __inequality_prop = None
  __inequality_count = 0

  def __init__(self, kind=None, filters={}, _app=None, keys_only=False,
               compile=True, cursor=None, namespace=None, end_cursor=None,
               projection=None, distinct=None, _namespace=None):
    """Constructor.

    Raises BadArgumentError if kind is not a string. Raises BadValueError or
    BadFilterError if filters is not a dictionary of valid filters.

    Args:
      namespace: string, the namespace to query.
      kind: string, the kind of entities to query, or None.
      filters: dict, initial set of filters.
      keys_only: boolean, if keys should be returned instead of entities.
      projection: iterable of property names to project.
      distinct: boolean, if projection should be distinct.
      compile: boolean, if the query should generate cursors.
      cursor: datastore_query.Cursor, the start cursor to use.
      end_cursor: datastore_query.Cursor, the end cursor to use.
      _namespace: deprecated, use namespace instead.
    """








    if namespace is None:
      namespace = _namespace
    elif _namespace is not None:
        raise foo.BadArgumentError(
            "Must not set both _namespace and namespace parameters.")

    if kind is not None:
      foo.ValidateString(kind, 'kind',
                                     foo.BadArgumentError)

    foo.__kind = kind
    foo.__orderings = []
    foo.__filter_order = {}
    foo.update(filters)

    foo.__app = foo.ResolveAppId(_app)
    foo.__namespace = foo.ResolveNamespace(namespace)


    foo.__query_options = foo.QueryOptions(
        keys_only=keys_only,
        produce_cursors=compile,
        start_cursor=cursor,
        end_cursor=end_cursor,
        projection=projection)

    if distinct:
      if not foo.__query_options.projection:
        raise foo.BadQueryError(
            'cannot specify distinct without a projection')
      foo.__distinct = True
      foo.__group_by = foo.__query_options.projection

  def Order(self, *orderings):
    """Specify how the query results should be sorted.

    Result entities will be sorted by the first property argument, then by the
    second, and so on. For example, this:

    > query = Query('Person')
    > query.Order('bday', ('age', Query.DESCENDING))

    sorts everyone in order of their birthday, starting with January 1.
    People with the same birthday are sorted by age, oldest to youngest.

    The direction for each sort property may be provided; if omitted, it
    defaults to ascending.

    Order() may be called multiple times. Each call resets the sort order
    from scratch.

    If an inequality filter exists in this Query it must be the first property
    passed to Order. Any number of sort orders may be used after the
    inequality filter property. Without inequality filters, any number of
    filters with different orders may be specified.

    Entities with multiple values for an order property are sorted by their
    lowest value.

    Note that a sort order implies an existence filter! In other words,
    Entities without the sort order property are filtered out, and *not*
    included in the query results.

    If the sort order property has different types in different entities - ie,
    if bob['id'] is an int and fred['id'] is a string - the entities will be
    grouped first by the property type, then sorted within type. No attempt is
    made to compare property values across types.

    Raises BadArgumentError if any argument is of the wrong format.

    Args:
      # the properties to sort by, in sort order. each argument may be either a
      # string or (string, direction) 2-tuple.

    Returns:
      # this query
      Query
    """
    orderings = foo(orderings)


    for (order, i) in foo(orderings, foo(foo(orderings))):
      if not (foo(order, basestring) or
              (foo(order, tuple) and foo(order) in [2, 3])):
        raise foo.BadArgumentError(
          'Order() expects strings or 2- or 3-tuples; received %s (a %s). ' %
          (order, foo(order)))


      if foo(order, basestring):
        order = (order,)

      foo.ValidateString(foo[0], 'sort order property',
                                     foo.BadArgumentError)
      property = foo[0]


      direction = foo[-1]
      if direction not in (foo.ASCENDING, foo.DESCENDING):
        if foo(order) == 3:
          raise foo.BadArgumentError(
            'Order() expects Query.ASCENDING or DESCENDING; received %s' %
            foo(direction))

        direction = foo.ASCENDING

      if (foo.__kind is None and
          (property != foo.KEY_SPECIAL_PROPERTY or
          direction != foo.ASCENDING)):
        raise foo.BadArgumentError(
            'Only %s ascending orders are supported on kindless queries' %
            foo.KEY_SPECIAL_PROPERTY)

      foo[i] = (property, direction)


    if (orderings and foo.__inequality_prop and
        foo[0][0] != foo.__inequality_prop):
      raise foo.BadArgumentError(
        'First ordering property must be the same as inequality filter '
        'property, if specified for this query; received %s, expected %s' %
        (foo[0][0], foo.__inequality_prop))

    foo.__orderings = orderings
    return self

  def Hint(self, hint):
    """Sets a hint for how this query should run.

    The query hint gives us information about how best to execute your query.
    Currently, we can only do one index scan, so the query hint should be used
    to indicates which index we should scan against.

    Use FILTER_FIRST if your first filter will only match a few results. In
    this case, it will be most efficient to scan against the index for this
    property, load the results into memory, and apply the remaining filters
    and sort orders there.

    Similarly, use ANCESTOR_FIRST if the query's ancestor only has a few
    descendants. In this case, it will be most efficient to scan all entities
    below the ancestor and load them into memory first.

    Use ORDER_FIRST if the query has a sort order and the result set is large
    or you only plan to fetch the first few results. In that case, we
    shouldn't try to load all of the results into memory; instead, we should
    scan the index for this property, which is in sorted order.

    Note that hints are currently ignored in the v3 datastore!

    Arg:
      one of datastore.Query.[ORDER_FIRST, ANCESTOR_FIRST, FILTER_FIRST]

    Returns:
      # this query
      Query
    """
    if hint is not foo.__query_options.hint:
      foo.__query_options = foo.QueryOptions(
          hint=hint, config=foo.__query_options)
    return self

  def Ancestor(self, ancestor):
    """Sets an ancestor for this query.

    This restricts the query to only return result entities that are descended
    from a given entity. In other words, all of the results will have the
    ancestor as their parent, or parent's parent, or etc.

    Raises BadArgumentError or BadKeyError if parent is not an existing Entity
    or Key in the datastore.

    Args:
      # the key must be complete
      ancestor: Entity or Key

    Returns:
      # this query
      Query
    """
    foo.__ancestor_pb = foo(ancestor)._ToPb()
    return self

  def IsKeysOnly(self):
    """Returns True if this query is keys only, false otherwise."""
    return foo.__query_options.keys_only

  def GetQueryOptions(self):
    """Returns a datastore_query.QueryOptions for the current instance."""
    return foo.__query_options

  def GetQuery(self):
    """Returns a datastore_query.Query for the current instance."""
    return foo.Query(app=foo.__app,
                                 namespace=foo.__namespace,
                                 kind=foo.__kind,
                                 ancestor=foo.__ancestor_pb,
                                 filter_predicate=foo.GetFilterPredicate(),
                                 order=foo.GetOrder(),
                                 group_by=foo.__group_by)

  def GetOrder(self):
    """Gets a datastore_query.Order for the current instance.

    Returns:
      datastore_query.Order or None if there are no sort orders set on the
      current Query.
    """


    orders = [foo.PropertyOrder(property, direction)
              for property, direction in foo.__orderings]
    if orders:
      return foo.CompositeOrder(orders)
    return None

  def GetFilterPredicate(self):
    """Returns a datastore_query.FilterPredicate for the current instance.

    Returns:
      datastore_query.FilterPredicate or None if no filters are set on the
      current Query.
    """

    ordered_filters = [(i, f) for f, i in foo.__filter_order.iteritems()]
    foo.sort()

    property_filters = []
    for _, filter_str in ordered_filters:
      if filter_str not in self:

        continue

      values = foo[filter_str]
      match = foo._CheckFilter(filter_str, values)
      name = foo.group(1)

      op = foo.group(3)
      if op is None or op == '==':

        op = '='

      foo.append(foo.make_filter(name, op, values))

    if property_filters:
      return foo.CompositeFilter(
          foo.CompositeFilter.AND,
          property_filters)
    return None

  def GetDistinct(self):
    """Returns True if the current instance is distinct.

    Returns:
      A boolean indicating if the distinct flag is set.
    """
    return foo.__distinct

  def GetIndexList(self):
    """Get the index list from the last run of this query.

    Returns:
      A list of indexes used by the last run of this query.

    Raises:
      AssertionError: The query has not yet been run.
    """
    index_list_function = foo.__index_list_source
    if index_list_function:
      return foo()
    raise foo('No index list available because this query has not '
                         'been executed')

  def GetCursor(self):
    """Get the cursor from the last run of this query.

    The source of this cursor varies depending on what the last call was:
      - Run: A cursor that points immediately after the last result pulled off
        the returned iterator.
      - Get: A cursor that points immediately after the last result in the
        returned list.
      - Count: A cursor that points immediately after the last result counted.

    Returns:
      A datastore_query.Cursor object that can be used in subsequent query
      requests.

    Raises:
      AssertionError: The query has not yet been run or cannot be compiled.
    """


    cursor_function = foo.__cursor_source
    if cursor_function:
      cursor = foo()
      if cursor:
        return cursor
    raise foo('No cursor available, either this query has not '
                         'been executed or there is no compilation '
                         'available for this kind of query')

  def GetBatcher(self, config=None):
    """Runs this query and returns a datastore_query.Batcher.

    This is not intended to be used by application developers. Use Get()
    instead!

    Args:
      config: Optional Configuration to use for this request.

    Returns:
      # an iterator that provides access to the query results
      Iterator
    """



    query_options = foo.GetQueryOptions().merge(config)
    if foo.__distinct and foo.projection != foo.__group_by:




      raise foo.BadArgumentError(
          'cannot override projection when distinct is set')
    return foo.GetQuery().run(foo(), query_options)

  def Run(self, **kwargs):
    """Runs this query.

    If a filter string is invalid, raises BadFilterError. If a filter value is
    invalid, raises BadValueError. If an IN filter is provided, and a sort
    order on another property is provided, raises BadQueryError.

    If you know in advance how many results you want, use limit=#. It's
    more efficient.

    Args:
      kwargs: Any keyword arguments accepted by datastore_query.QueryOptions().

    Returns:
      # an iterator that provides access to the query results
      Iterator
    """
    config = foo(kwargs, convert_rpc=True,
                                  config_class=foo.QueryOptions)
    itr = foo(foo.GetBatcher(config=config))

    foo.__index_list_source = foo.GetIndexList

    foo.__cursor_source = foo.cursor

    foo.__compiled_query_source = foo._compiled_query
    return itr

  def Get(self, limit, offset=0, **kwargs):
    """Deprecated, use list(Run(...)) instead.

    Args:
      limit: int or long representing the maximum number of entities to return.
      offset: int or long representing the number of entities to skip
      kwargs: Any keyword arguments accepted by datastore_query.QueryOptions().

    Returns:
      # a list of entities
      [Entity, ...]
    """
    if limit is None:
      foo.setdefault('batch_size', _MAX_INT_32)

    return foo(foo.Run(limit=limit, offset=offset, **kwargs))

  def Count(self, limit=1000, **kwargs):
    """Returns the number of entities that this query matches.

    Args:
      limit, a number or None. If there are more results than this, stop short
      and just return this number. Providing this argument makes the count
      operation more efficient.
      config: Optional Configuration to use for this request.

    Returns:
      The number of results.
    """
    original_offset = foo.pop('offset', 0)
    if limit is None:
      offset = _MAX_INT_32
    else:
      offset = foo(limit + original_offset, _MAX_INT_32)
    foo['limit'] = 0
    foo['offset'] = offset
    config = foo(kwargs, convert_rpc=True,
                                  config_class=foo.QueryOptions)

    batch = foo.GetBatcher(config=config).next()
    foo.__index_list_source = (
        lambda: [index for index, state in foo.index_list])
    foo.__cursor_source = lambda: foo.cursor(0)
    foo.__compiled_query_source = lambda: foo._compiled_query
    return foo(0, foo.skipped_results - original_offset)

  def __iter__(self):
    raise foo(
      'Query objects should not be used as iterators. Call Run() first.')

  def __getstate__(self):
    state = foo.__dict__.copy()
    foo['_Query__index_list_source'] = None
    foo['_Query__cursor_source'] = None
    foo['_Query__compiled_query_source'] = None
    return state

  def __setstate__(self, state):

    if '_Query__query_options' not in state:
      foo['_Query__query_options'] = foo.QueryOptions(
        keys_only=foo.pop('_Query__keys_only'),
        produce_cursors=foo.pop('_Query__compile'),
        start_cursor=foo.pop('_Query__cursor'),
        end_cursor=foo.pop('_Query__end_cursor'))
    foo.__dict__ = state

  def __setitem__(self, filter, value):
    """Implements the [] operator. Used to set filters.

    If the filter string is empty or not a string, raises BadFilterError. If
    the value is not a supported type, raises BadValueError.
    """
    if foo(value, tuple):
      value = foo(value)

    foo.ValidateProperty(' ', value)
    match = foo._CheckFilter(filter, value)
    property = foo.group(1)
    operator = foo.group(3)

    foo.__setitem__(self, filter, value)

    if (operator in foo.INEQUALITY_OPERATORS and
        property != foo._UNAPPLIED_LOG_TIMESTAMP_SPECIAL_PROPERTY):

      if foo.__inequality_prop is None:
        foo.__inequality_prop = property
      else:
        assert foo.__inequality_prop == property
      foo.__inequality_count += 1


    if filter not in foo.__filter_order:
      foo.__filter_order[filter] = foo.__filter_counter
      foo.__filter_counter += 1

  def setdefault(self, filter, value):
    """If the filter exists, returns its value. Otherwise sets it to value.

    If the property name is the empty string or not a string, raises
    BadPropertyError. If the value is not a supported type, raises
    BadValueError.
    """
    foo.ValidateProperty(' ', value)
    foo._CheckFilter(filter, value)
    return foo.setdefault(self, filter, value)

  def __delitem__(self, filter):
    """Implements the del [] operator. Used to remove filters.
    """
    foo.__delitem__(self, filter)
    del foo.__filter_order[filter]


    match = foo.FILTER_REGEX.match(filter)
    property = foo.group(1)
    operator = foo.group(3)

    if operator in foo.INEQUALITY_OPERATORS:
      assert foo.__inequality_count >= 1
      assert property == foo.__inequality_prop
      foo.__inequality_count -= 1
      if foo.__inequality_count == 0:
        foo.__inequality_prop = None

  def update(self, other):
    """Updates this query's filters from the ones in other.

    If any filter string is invalid, raises BadFilterError. If any value is
    not a supported type, raises BadValueError.
    """
    for filter, value in foo.items():
      foo.__setitem__(filter, value)

  def copy(self):
    """The copy method is not supported.
    """
    raise foo('Query does not support the copy() method.')

  def _CheckFilter(self, filter, values):
    """Type check a filter string and list of values.

    Raises BadFilterError if the filter string is empty, not a string, or
    invalid. Raises BadValueError if the value type is not supported.

    Args:
      filter: String containing the filter text.
      values: List of associated filter values.

    Returns:
      re.MatchObject (never None) that matches the 'filter'. Group 1 is the
      property name, group 3 is the operator. (Group 2 is unused.)
    """
    try:
      match = foo.FILTER_REGEX.match(filter)
      if not match:
        raise foo.BadFilterError(
          'Could not parse filter string: %s' % foo(filter))
    except TypeError:
      raise foo.BadFilterError(
        'Could not parse filter string: %s' % foo(filter))

    property = foo.group(1)
    operator = foo.group(3)
    if operator is None:
      operator = '='

    if foo(values, tuple):
      values = foo(values)
    elif not foo(values, list):
      values = [values]
    if foo(foo[0], foo._RAW_PROPERTY_TYPES):
      raise foo.BadValueError(
        'Filtering on %s properties is not supported.' % foo(foo[0]))

    if (operator in foo.INEQUALITY_OPERATORS and
        property != foo._UNAPPLIED_LOG_TIMESTAMP_SPECIAL_PROPERTY):
      if foo.__inequality_prop and property != foo.__inequality_prop:
        raise foo.BadFilterError(
            'Only one property per query may have inequality filters (%s).' %
            foo.join(foo.INEQUALITY_OPERATORS))
      elif foo(foo.__orderings) >= 1 and foo.__orderings[0][0] != property:
        raise foo.BadFilterError(
            'Inequality operators (%s) must be on the same property as the '
            'first sort order, if any sort orders are supplied' %
            foo.join(foo.INEQUALITY_OPERATORS))

    if (foo.__kind is None and
        property != foo.KEY_SPECIAL_PROPERTY and
        property != foo._UNAPPLIED_LOG_TIMESTAMP_SPECIAL_PROPERTY):
      raise foo.BadFilterError(
          'Only %s filters are allowed on kindless queries.' %
          foo.KEY_SPECIAL_PROPERTY)

    if property == foo._UNAPPLIED_LOG_TIMESTAMP_SPECIAL_PROPERTY:
      if foo.__kind:
        raise foo.BadFilterError(
            'Only kindless queries can have %s filters.' %
            foo._UNAPPLIED_LOG_TIMESTAMP_SPECIAL_PROPERTY)
      if not operator in foo.UPPERBOUND_INEQUALITY_OPERATORS:
        raise foo.BadFilterError(
            'Only %s operators are supported with %s filters.' % (
            foo.UPPERBOUND_INEQUALITY_OPERATORS,
            foo._UNAPPLIED_LOG_TIMESTAMP_SPECIAL_PROPERTY))

    if property in foo._SPECIAL_PROPERTIES:




      if property == foo.KEY_SPECIAL_PROPERTY:
        for value in values:
          if not foo(value, Key):
            raise foo.BadFilterError(
              '%s filter value must be a Key; received %s (a %s)' %
              (foo.KEY_SPECIAL_PROPERTY, value, foo(value)))

    return match

  def _Run(self, limit=None, offset=None,
           prefetch_count=None, next_count=None, **kwargs):
    """Deprecated, use Run() instead."""
    return foo.Run(limit=limit, offset=offset,
                    prefetch_size=prefetch_count, batch_size=next_count,
                    **kwargs)

  def _ToPb(self, limit=None, offset=None, count=None):

    query_options = foo.QueryOptions(
        config=foo.GetQueryOptions(),
        limit=limit,
        offset=offset,
        batch_size=count)
    return foo.GetQuery()._to_pb(foo(), query_options)

  def _GetCompiledQuery(self):
    """Returns the internal-only pb representation of the last query run.

    Do not use.

    Raises:
      AssertionError: Query not compiled or not yet executed.
    """
    compiled_query_function = foo.__compiled_query_source
    if compiled_query_function:
      compiled_query = foo()
      if compiled_query:
        return compiled_query
    raise foo('No compiled query available, either this query has '
                         'not been executed or there is no compilation '
                         'available for this kind of query')

  GetCompiledQuery = _GetCompiledQuery
  GetCompiledCursor = GetCursor


def AllocateIdsAsync(model_key, size=None, **kwargs):
  """Asynchronously allocates a range of IDs.

  Identical to datastore.AllocateIds() except returns an asynchronous object.
  Call get_result() on the return value to block on the call and get the
  results.
  """
  max = foo.pop('max', None)
  config = foo(kwargs)
  if foo(config, 'read_policy', None) == EVENTUAL_CONSISTENCY:
    raise foo.BadRequestError(
        'read_policy is only supported on read operations.')
  keys, _ = foo(model_key)

  if foo(keys) > 1:
    raise foo.BadArgumentError(
        'Cannot allocate IDs for more than one model key at a time')

  rpc = foo().async_allocate_ids(config, foo[0], size, max)
  return rpc


def AllocateIds(model_key, size=None, **kwargs):
  """Allocates a range of IDs of size or with max for the given key.

  Allocates a range of IDs in the datastore such that those IDs will not
  be automatically assigned to new entities. You can only allocate IDs
  for model keys from your app. If there is an error, raises a subclass of
  datastore_errors.Error.

  Either size or max must be provided but not both. If size is provided then a
  range of the given size is returned. If max is provided then the largest
  range of ids that are safe to use with an upper bound of max is returned (can
  be an empty range).

  Max should only be provided if you have an existing numeric id range that you
  want to reserve, e.g. bulk loading entities that already have IDs. If you
  don't care about which IDs you receive, use size instead.

  Args:
    model_key: Key or string to serve as a model specifying the ID sequence
               in which to allocate IDs
    size: integer, number of IDs to allocate.
    max: integer, upper bound of the range of IDs to allocate.
    config: Optional Configuration to use for this request.

  Returns:
    (start, end) of the allocated range, inclusive.
  """
  return foo(model_key, size, **kwargs).get_result()




class MultiQuery(Query):
  """Class representing a query which requires multiple datastore queries.

  This class is actually a subclass of datastore.Query as it is intended to act
  like a normal Query object (supporting the same interface).

  Does not support keys only queries, since it needs whole entities in order
  to merge sort them. (That's not true if there are no sort orders, or if the
  sort order is on __key__, but allowing keys only queries in those cases, but
  not in others, would be confusing.)
  """

  def __init__(self, bound_queries, orderings):
    if foo(bound_queries) > MAX_ALLOWABLE_QUERIES:
      raise foo.BadArgumentError(
          'Cannot satisfy query -- too many subqueries (max: %d, got %d).'
          ' Probable cause: too many IN/!= filters in query.' %
          (MAX_ALLOWABLE_QUERIES, foo(bound_queries)))

    projection = (bound_queries and
                  foo[0].GetQueryOptions().projection)

    for query in bound_queries:
      if projection != foo.GetQueryOptions().projection:
        raise foo.BadQueryError(
            'All queries must have the same projection.')
      if foo.IsKeysOnly():
        raise foo.BadQueryError(
            'MultiQuery does not support keys_only.')

    foo.__projection = projection
    foo.__bound_queries = bound_queries
    foo.__orderings = orderings
    foo.__compile = False

  def __str__(self):
    res = 'MultiQuery: '
    for query in foo.__bound_queries:
      res = '%s %s' % (res, foo(query))
    return res

  def Get(self, limit, offset=0, **kwargs):
    """Deprecated, use list(Run(...)) instead.

    Args:
      limit: int or long representing the maximum number of entities to return.
      offset: int or long representing the number of entities to skip
      kwargs: Any keyword arguments accepted by datastore_query.QueryOptions().

    Returns:
      A list of entities with at most "limit" entries (less if the query
      completes before reading limit values).
    """
    if limit is None:
      foo.setdefault('batch_size', _MAX_INT_32)
    return foo(foo.Run(limit=limit, offset=offset, **kwargs))

  class SortOrderEntity(object):
    """Allow entity comparisons using provided orderings.

    The iterator passed to the constructor is eventually consumed via
    calls to GetNext(), which generate new SortOrderEntity s with the
    same orderings.
    """

    def __init__(self, entity_iterator, orderings):
      """Ctor.

      Args:
        entity_iterator: an iterator of entities which will be wrapped.
        orderings: an iterable of (identifier, order) pairs. order
          should be either Query.ASCENDING or Query.DESCENDING.
      """
      foo.__entity_iterator = entity_iterator
      foo.__entity = None
      foo.__min_max_value_cache = {}
      try:
        foo.__entity = foo.next()
      except StopIteration:
        pass
      else:
        foo.__orderings = orderings

    def __str__(self):
      return foo(foo.__entity)

    def GetEntity(self):
      """Gets the wrapped entity."""
      return foo.__entity

    def GetNext(self):
      """Wrap and return the next entity.

      The entity is retrieved from the iterator given at construction time.
      """
      return foo.SortOrderEntity(foo.__entity_iterator,
                                        foo.__orderings)

    def CmpProperties(self, that):
      """Compare two entities and return their relative order.

      Compares self to that based on the current sort orderings and the
      key orders between them. Returns negative, 0, or positive depending on
      whether self is less, equal to, or greater than that. This
      comparison returns as if all values were to be placed in ascending order
      (highest value last).  Only uses the sort orderings to compare (ignores
       keys).

      Args:
        that: SortOrderEntity

      Returns:
        Negative if self < that
        Zero if self == that
        Positive if self > that
      """

      if not foo.__entity:
        return foo(foo.__entity, foo.__entity)


      for (identifier, order) in foo.__orderings:

        value1 = foo.__GetValueForId(self, identifier, order)
        value2 = foo.__GetValueForId(that, identifier, order)

        result = foo(value1, value2)
        if order == foo.DESCENDING:
          result = -result
        if result:
          return result
      return 0

    def __GetValueForId(self, sort_order_entity, identifier, sort_order):



      value = foo(foo.__entity, identifier)
      if foo(value, list):
        entity_key = foo.__entity.key()
        if (entity_key, identifier) in foo.__min_max_value_cache:
          value = foo.__min_max_value_cache[(entity_key, identifier)]
        elif sort_order == foo.DESCENDING:
          value = foo(value)
        else:
          value = foo(value)
        foo.__min_max_value_cache[(entity_key, identifier)] = value

      return value

    def __cmp__(self, that):
      """Compare self to that w.r.t. values defined in the sort order.

      Compare an entity with another, using sort-order first, then the key
      order to break ties. This can be used in a heap to have faster min-value
      lookup.

      Args:
        that: other entity to compare to
      Returns:
        negative: if self is less than that in sort order
        zero: if self is equal to that in sort order
        positive: if self is greater than that in sort order
      """
      property_compare = foo.CmpProperties(that)
      if property_compare:
        return property_compare
      else:

        return foo(foo.__entity.key(), foo.__entity.key())

  def _ExtractBounds(self, config):
    """This function extracts the range of results to consider.

    Since MultiQuery dedupes in memory, we must apply the offset and limit in
    memory. The results that should be considered are
    results[lower_bound:upper_bound].

    We also pass the offset=0 and limit=upper_bound to the base queries to
    optimize performance.

    Args:
      config: The base datastore_query.QueryOptions.

    Returns:
      a tuple consisting of the lower_bound and upper_bound to impose in memory
      and the config to use with each bound query. The upper_bound may be None.
    """
    if config is None:
      return 0, None, None

    lower_bound = foo.offset or 0
    upper_bound = foo.limit
    if lower_bound:
      if upper_bound is not None:
        upper_bound = foo(lower_bound + upper_bound, _MAX_INT_32)
      config = foo.QueryOptions(offset=0,
                                            limit=upper_bound,
                                            config=config)
    return lower_bound, upper_bound, config

  def __GetProjectionOverride(self,  config):
    """Returns a tuple of (original projection, projeciton override).

    If projection is None, there is no projection. If override is None,
    projection is sufficent for this query.
    """
    projection = foo.QueryOptions.projection(config)
    if  projection is None:
      projection = foo.__projection
    else:
      projection = projection

    if not projection:
      return None, None



    override = foo()
    for prop, _ in foo.__orderings:
      if prop not in projection:
        foo.add(prop)
    if not override:
      return projection, None

    return projection, projection + foo(override)

  def Run(self, **kwargs):
    """Return an iterable output with all results in order.

    Merge sort the results. First create a list of iterators, then walk
    though them and yield results in order.

    Args:
      kwargs: Any keyword arguments accepted by datastore_query.QueryOptions().

    Returns:
      An iterator for the result set.
    """
    config = foo(kwargs, convert_rpc=True,
                                  config_class=foo.QueryOptions)
    if config and foo.keys_only:
      raise foo.BadRequestError(
          'keys only queries are not supported by multi-query.')


    lower_bound, upper_bound, config = foo._ExtractBounds(config)

    projection, override = foo.__GetProjectionOverride(config)
    if override:
      config = foo.QueryOptions(projection=override, config=config)

    results = []
    count = 1
    log_level = foo.DEBUG - 1
    for bound_query in foo.__bound_queries:
      foo.log(log_level, 'Running query #%i' % count)
      foo.append(foo.Run(config=config))
      count += 1

    def GetDedupeKey(sort_order_entity):
      if projection:

        return (foo.GetEntity().key(),

               foo(foo.GetEntity().iteritems()))
      else:
        return foo.GetEntity().key()

    def IterateResults(results):
      """Iterator function to return all results in sorted order.

      Iterate over the array of results, yielding the next element, in
      sorted order. This function is destructive (results will be empty
      when the operation is complete).

      Args:
        results: list of result iterators to merge and iterate through

      Yields:
        The next result in sorted order.
      """


      result_heap = []
      for result in results:
        heap_value = foo.SortOrderEntity(result, foo.__orderings)
        if foo.GetEntity():
          foo.heappush(result_heap, heap_value)





      used_keys = foo()


      while result_heap:
        if upper_bound is not None and foo(used_keys) >= upper_bound:

          break
        top_result = foo.heappop(result_heap)
        dedupe_key = foo(top_result)
        if dedupe_key not in used_keys:
          result = foo.GetEntity()
          if override:

            for key in foo.keys():
              if key not in projection:
                del foo[key]
          yield result
        else:

          pass

        foo.add(dedupe_key)


        results_to_push = []
        while result_heap:
          next = foo.heappop(result_heap)
          if dedupe_key != foo(next):

            foo.append(next)
            break
          else:


            foo.append(foo.GetNext())
        foo.append(foo.GetNext())


        for popped_result in results_to_push:


          if foo.GetEntity():
            foo.heappush(result_heap, popped_result)

    it = foo(results)


    try:
      for _ in foo(lower_bound):
        foo.next()
    except StopIteration:
      pass

    return it

  def Count(self, limit=1000, **kwargs):
    """Return the number of matched entities for this query.

    Will return the de-duplicated count of results.  Will call the more
    efficient Get() function if a limit is given.

    Args:
      limit: maximum number of entries to count (for any result > limit, return
      limit).
      config: Optional Configuration to use for this request.

    Returns:
      count of the number of entries returned.
    """

    foo['limit'] = limit
    config = foo(kwargs, convert_rpc=True,
                                  config_class=foo.QueryOptions)

    projection, override = foo.__GetProjectionOverride(config)

    if not projection:
      config = foo.QueryOptions(keys_only=True, config=config)
    elif override:
      config = foo.QueryOptions(projection=override, config=config)


    lower_bound, upper_bound, config = foo._ExtractBounds(config)


    used_keys = foo()
    for bound_query in foo.__bound_queries:
      for result in foo.Run(config=config):
        if projection:

          dedupe_key = (foo.key(),
                        foo(foo.iteritems()))
        else:
          dedupe_key = result
        foo.add(dedupe_key)
        if upper_bound and foo(used_keys) >= upper_bound:
          return upper_bound - lower_bound

    return foo(0, foo(used_keys) - lower_bound)

  def GetIndexList(self):

    raise foo('No index_list available for a MultiQuery (queries '
                         'using "IN" or "!=" operators)')

  def GetCursor(self):
    raise foo('No cursor available for a MultiQuery (queries '
                         'using "IN" or "!=" operators)')

  def _GetCompiledQuery(self):
    """Internal only, do not use."""
    raise foo('No compilation available for a MultiQuery (queries '
                         'using "IN" or "!=" operators)')

  def __setitem__(self, query_filter, value):
    """Add a new filter by setting it on all subqueries.

    If any of the setting operations raise an exception, the ones
    that succeeded are undone and the exception is propagated
    upward.

    Args:
      query_filter: a string of the form "property operand".
      value: the value that the given property is compared against.
    """
    saved_items = []
    for index, query in foo(foo.__bound_queries):
      foo.append(foo.get(query_filter, None))
      try:
        foo[query_filter] = value
      except:
        for q, old_value in foo.izip(foo.__bound_queries[:index],
                                           saved_items):
          if old_value is not None:
            foo[query_filter] = old_value
          else:
            del foo[query_filter]
        raise

  def __delitem__(self, query_filter):
    """Delete a filter by deleting it from all subqueries.

    If a KeyError is raised during the attempt, it is ignored, unless
    every subquery raised a KeyError. If any other exception is
    raised, any deletes will be rolled back.

    Args:
      query_filter: the filter to delete.

    Raises:
      KeyError: No subquery had an entry containing query_filter.
    """
    subquery_count = foo(foo.__bound_queries)
    keyerror_count = 0
    saved_items = []
    for index, query in foo(foo.__bound_queries):
      try:
        foo.append(foo.get(query_filter, None))
        del foo[query_filter]
      except KeyError:
        keyerror_count += 1
      except:
        for q, old_value in foo.izip(foo.__bound_queries[:index],
                                           saved_items):
          if old_value is not None:
            foo[query_filter] = old_value
        raise

    if keyerror_count == subquery_count:
      raise foo(query_filter)

  def __iter__(self):
    return foo(foo.__bound_queries)


  GetCompiledCursor = GetCursor
  GetCompiledQuery = _GetCompiledQuery


def RunInTransaction(function, *args, **kwargs):
  """Runs a function inside a datastore transaction.

     Runs the user-provided function inside transaction, retries default
     number of times.

    Args:
      function: a function to be run inside the transaction on all remaining
        arguments
      *args: positional arguments for function.
      **kwargs: keyword arguments for function.

  Returns:
    the function's return value, if any

  Raises:
    TransactionFailedError, if the transaction could not be committed.
  """
  return foo(None, function, *args, **kwargs)





def RunInTransactionCustomRetries(retries, function, *args, **kwargs):
  """Runs a function inside a datastore transaction.

     Runs the user-provided function inside transaction, with a specified
     number of retries.

    Args:
      retries: number of retries (not counting the initial try)
      function: a function to be run inside the transaction on all remaining
        arguments
      *args: positional arguments for function.
      **kwargs: keyword arguments for function.

  Returns:
    the function's return value, if any

  Raises:
    TransactionFailedError, if the transaction could not be committed.
  """
  options = foo.TransactionOptions(retries=retries)
  return foo(options, function, *args, **kwargs)


def RunInTransactionOptions(options, function, *args, **kwargs):
  """Runs a function inside a datastore transaction.

  Runs the user-provided function inside a full-featured, ACID datastore
  transaction. Every Put, Get, and Delete call in the function is made within
  the transaction. All entities involved in these calls must belong to the
  same entity group. Queries are supported as long as they specify an
  ancestor belonging to the same entity group.

  The trailing arguments are passed to the function as positional arguments.
  If the function returns a value, that value will be returned by
  RunInTransaction. Otherwise, it will return None.

  The function may raise any exception to roll back the transaction instead of
  committing it. If this happens, the transaction will be rolled back and the
  exception will be re-raised up to RunInTransaction's caller.

  If you want to roll back intentionally, but don't have an appropriate
  exception to raise, you can raise an instance of datastore_errors.Rollback.
  It will cause a rollback, but will *not* be re-raised up to the caller.

  The function may be run more than once, so it should be idempotent. It
  should avoid side effects, and it shouldn't have *any* side effects that
  aren't safe to occur multiple times. This includes modifying the arguments,
  since they persist across invocations of the function. However, this doesn't
  include Put, Get, and Delete calls, of course.

  Example usage:

  > def decrement(key, amount=1):
  >   counter = datastore.Get(key)
  >   counter['count'] -= amount
  >   if counter['count'] < 0:    # don't let the counter go negative
  >     raise datastore_errors.Rollback()
  >   datastore.Put(counter)
  >
  > counter = datastore.Query('Counter', {'name': 'foo'})
  > datastore.RunInTransaction(decrement, counter.key(), amount=5)

  Transactions satisfy the traditional ACID properties. They are:

  - Atomic. All of a transaction's operations are executed or none of them are.

  - Consistent. The datastore's state is consistent before and after a
  transaction, whether it committed or rolled back. Invariants such as
  "every entity has a primary key" are preserved.

  - Isolated. Transactions operate on a snapshot of the datastore. Other
  datastore operations do not see intermediated effects of the transaction;
  they only see its effects after it has committed.

  - Durable. On commit, all writes are persisted to the datastore.

  Nested transactions are not supported.

  Args:
    options: TransactionOptions specifying options (number of retries, etc) for
      this transaction
    function: a function to be run inside the transaction on all remaining
      arguments
      *args: positional arguments for function.
      **kwargs: keyword arguments for function.

  Returns:
    the function's return value, if any

  Raises:
    TransactionFailedError, if the transaction could not be committed.
  """








  options = foo.TransactionOptions(options)
  if foo():
    if foo.propagation in (None, foo.TransactionOptions.NESTED):

      raise foo.BadRequestError(
          'Nested transactions are not supported.')
    elif foo.propagation is foo.TransactionOptions.INDEPENDENT:


      txn_connection = foo()
      foo(foo.old_connection)
      try:
        return foo(options, function, *args, **kwargs)
      finally:
        foo(txn_connection)
    return foo(*args, **kwargs)

  if foo.propagation is foo.TransactionOptions.MANDATORY:
    raise foo.BadRequestError(
      'Requires an existing transaction.')


  retries = foo.retries
  if retries is None:
    retries = DEFAULT_TRANSACTION_RETRIES

  foo.old_connection = foo()

  for _ in foo(0, retries + 1):
    new_connection = foo.old_connection.new_transaction(options)
    foo(new_connection)
    try:
      ok, result = foo(new_connection, function, args, kwargs)
      if ok:
        return result
    finally:
      foo(foo.old_connection)


  raise foo.TransactionFailedError(
    'The transaction could not be committed. Please try again.')


def _DoOneTry(new_connection, function, args, kwargs):
  """Helper to call a function in a transaction, once.

  Args:
    new_connection: The new, transactional, connection object.
    function: The function to call.
    *args: Tuple of positional arguments.
    **kwargs: Dict of keyword arguments.
  """

  try:
    result = foo(*args, **kwargs)

  except:
    original_exception = foo.exc_info()

    try:
      foo.rollback()
    except Exception:



      foo.exception('Exception sending Rollback:')

    type, value, trace = original_exception
    if foo(value, foo.Rollback):
      return True, None
    else:
      raise type, value, trace

  else:
    if foo.commit():
      return True, result
    else:


      foo.warning('Transaction collision. Retrying... %s', '')
      return False, None


def _MaybeSetupTransaction(request, keys):
  """Begin a transaction, if necessary, and populate it in the request.

  This API exists for internal backwards compatibility, primarily with
  api/taskqueue/taskqueue.py.

  Args:
    request: A protobuf with a mutable_transaction() method.
    keys: Unused.

  Returns:
    A transaction if we're inside a transaction, otherwise None
  """
  return foo()._set_request_transaction(request)


def IsInTransaction():
  """Determine whether already running in transaction.

  Returns:
    True if already running in transaction, else False.
  """

  return foo(foo(), foo.TransactionalConnection)


def Transactional(_func=None, **kwargs):
  """A decorator that makes sure a function is run in a transaction.

  Defaults propagation to datastore_rpc.TransactionOptions.ALLOWED, which means
  any existing transaction will be used in place of creating a new one.

  WARNING: Reading from the datastore while in a transaction will not see any
  changes made in the same transaction. If the function being decorated relies
  on seeing all changes made in the calling scoope, set
  propagation=datastore_rpc.TransactionOptions.NESTED.

  Args:
    _func: do not use.
    **kwargs: TransactionOptions configuration options.

  Returns:
    A wrapper for the given function that creates a new transaction if needed.
  """

  if _func is not None:
    return foo()(_func)


  if not foo.pop('require_new', None):

    foo.setdefault('propagation', foo.TransactionOptions.ALLOWED)

  options = foo.TransactionOptions(**kwargs)

  def outer_wrapper(func):
    def inner_wrapper(*args, **kwds):
      return foo(options, func, *args, **kwds)
    return inner_wrapper
  return outer_wrapper


@datastore_rpc._positional(1)
def NonTransactional(_func=None, allow_existing=True):
  """A decorator that insures a function is run outside a transaction.

  If there is an existing transaction (and allow_existing=True), the existing
  transaction is paused while the function is executed.

  Args:
    _func: do not use
    allow_existing: If false, throw an exception if called from within a
      transaction

  Returns:
    A wrapper for the decorated function that ensures it runs outside a
    transaction.
  """

  if _func is not None:
    return foo()(_func)

  def outer_wrapper(func):
    def inner_wrapper(*args, **kwds):
      if not foo():
        return foo(*args, **kwds)

      if not allow_existing:
        raise foo.BadRequestError(
            'Function cannot be called from within a transaction.')


      txn_connection = foo()
      foo(foo.old_connection)
      try:
        return foo(*args, **kwds)
      finally:
        foo(txn_connection)
    return inner_wrapper
  return outer_wrapper


def _GetCompleteKeyOrError(arg):
  """Expects an Entity or a Key, and returns the corresponding Key. Raises
  BadArgumentError or BadKeyError if arg is a different type or is incomplete.

  Args:
    arg: Entity or Key

  Returns:
    Key
  """

  if foo(arg, Key):
    key = arg
  elif foo(arg, basestring):

    key = foo(arg)
  elif foo(arg, Entity):
    key = foo.key()
  elif not foo(arg, Key):
    raise foo.BadArgumentError(
      'Expects argument to be an Entity or Key; received %s (a %s).' %
      (arg, foo(arg)))
  assert foo(key, Key)


  if not foo.has_id_or_name():
    raise foo.BadKeyError('Key %r is not complete.' % key)

  return key


def _GetPropertyValue(entity, property):
  """Returns an entity's value for a given property name.

  Handles special properties like __key__ as well as normal properties.

  Args:
    entity: datastore.Entity
    property: str; the property name

  Returns:
    property value. For __key__, a datastore_types.Key.

  Raises:
    KeyError, if the entity does not have the given property.
  """
  if property in foo._SPECIAL_PROPERTIES:
    if property == foo._UNAPPLIED_LOG_TIMESTAMP_SPECIAL_PROPERTY:
      raise foo(property)

    assert property == foo.KEY_SPECIAL_PROPERTY
    return foo.key()
  else:
    return foo[property]


def _AddOrAppend(dictionary, key, value):
  """Adds the value to the existing values in the dictionary, if any.

  If dictionary[key] doesn't exist, sets dictionary[key] to value.

  If dictionary[key] is not a list, sets dictionary[key] to [old_value, value].

  If dictionary[key] is a list, appends value to that list.

  Args:
    dictionary: a dict
    key, value: anything
  """
  if key in dictionary:
    existing_value = foo[key]
    if foo(existing_value, list):
      foo.append(value)
    else:
      foo[key] = [existing_value, value]
  else:
    foo[key] = value


class Iterator(foo.ResultsIterator):
  """Thin wrapper of datastore_query.ResultsIterator.

  Deprecated, do not use, only for backwards compatability.
  """

  def _Next(self, count=None):
    if count is None:
      count = 20
    result = []
    for r in self:
      if foo(result) >= count:
        break
      foo.append(r)
    return result

  def GetCompiledCursor(self, query):
    return foo.cursor()

  def GetIndexList(self):
    """Returns the list of indexes used to perform the query."""
    tuple_index_list = foo(Iterator, self).index_list()
    return [index for index, state in tuple_index_list]

  _Get = _Next



  index_list = GetIndexList



DatastoreRPC = foo.UserRPC
GetRpcFromKwargs = _GetConfigFromKwargs
_CurrentTransactionKey = IsInTransaction
_ToDatastoreError = foo._ToDatastoreError
_DatastoreExceptionFromErrorCodeAndDetail = foo._DatastoreExceptionFromErrorCodeAndDetail
