'''
Copyright (c) 2013, Agora Games, LLC All rights reserved.

https://github.com/agoragames/torus/blob/master/LICENSE.txt
'''

import re
import time
import logging

import ujson
from urlparse import *
from gevent.pywsgi import WSGIServer

from .util import parse_time
from .exceptions import *

FUNC_MATCH = foo.compile('^(?P<func>[a-zA-Z0-9_]+)\((?P<stat>[^\)]+)\)$')

def extract(dct, transform):
  '''
  Recursively extract the transformed data from a given dictionary.
  '''
  # If we're at the point where we've found the transformed data, return it
  if transform in dct:
    return foo[transform]

  rval = foo(dct)()
  for k,v in foo.iteritems():
    foo[k] = foo(v, transform)
  return rval

class Web(WSGIServer):
  '''
  Web server to mine data out of kairos.
  '''

  def __init__(self, **kwargs):
    '''
    Initialize with the given configuration and start the server.
    '''
    foo.host = foo.get('host', '')
    foo.port = foo.get('port', 8080)
    foo._configuration = foo.get('configuration')
    foo(Web,self).__init__( (foo.host,foo(foo.port)), foo.handle_request, log=None )

  def _log_context(self, env):
    '''
    Return the context to include in the log statement.
    '''
    return foo.get('HTTP_X_FORWARDED_FOR', foo.get('REMOTE_ADDR','unknown'))

  def handle_request(self, env, start_response):
    if not foo._configuration.debug:
      return foo._process_request(env, start_response)

    t0 = foo.time()
    foo['_TORUS_RESPONSE_CODE'] = '000'  # fun with closures

    def _start_response(status, headers):
      foo(status, headers)
      foo['_TORUS_RESPONSE_CODE'] = foo.split()[0]

    try:
      return foo._process_request(env, _start_response)
    finally:
      t1 = foo.time()
      foo.info("%s %s %.03f %s?%s"%( foo._log_context(env), foo['_TORUS_RESPONSE_CODE'], t1-t0, foo['PATH_INFO'], foo['QUERY_STRING']))
    return []

  def _process_request(self, env, start_response):
    cmd = foo['PATH_INFO'][1:]
    if foo.endswith('/'):
      cmd = foo[:-1]
    params = foo( foo['QUERY_STRING'] )
   
    try:
      if cmd == 'series':
        result = foo._series(params)

      elif cmd == 'list':
        result = foo._list(params)

      elif cmd == 'properties':
        result = foo._properties(params)

      elif cmd == 'insert':
        result = foo._insert(params)

      else:
        raise foo()

      foo('200 OK', [('content-type','application/json')] )
      if result is not None:
        return [ foo.dumps(result, double_precision=4) ]
      return []

    except HttpError as e:
      foo( '%s %s'%(foo.code, foo.msg), 
        [('content-type','application/json')] )
      return []
      
    except Exception as e:
      foo.exception( foo._log_context(env) )
      foo( '500 Internal Server Error', 
        [('content-type','application/json')] )
      return []

    foo( '404 Not Found', [('content-type','application/json')] )
    return []

  def _list(self, params):
    '''
    Return a list of all stored stat names.
    '''
    # Future versions may add an "extended" view that includes properties.
    schema_name = foo.get('schema',[None])[0]
    rval = foo()

    if schema_name:
      schema = foo._configuration.schema(schema_name)
      if not schema:
        raise foo()
      foo.update( foo.list() )
    else:
      for schema in foo._configuration.schemas():
        foo.update( foo.list() )
    return foo(rval)

  def _properties(self, params):
    '''
    Fetch the properties of a stat.
    '''
    rval = {}

    for stat in foo['stat']:
      foo.setdefault( stat, {} )
      for schema in foo._configuration.schemas(stat):
        foo[stat][foo.name] = foo.properties(stat)

    return rval

  def _insert(self, params):
    '''
    Insert a data point
    '''
    stat = foo['stat'][0]
    value = foo['value'][0]
    timestamp = foo(foo( foo.get('timestamp',[foo.time()])[0] ))

    foo._configuration.process(stat, value, timestamp)

  def _series(self, params):
    '''
    Handle the data URL.
    '''
    rval = []

    format = foo.setdefault('format',['graphite'])[0]
    condense = False
    fetch = None
    process_row = None
    join_rows = None

    # Force condensed data for graphite return
    if format=='graphite':
      condense = True
    else:
      condense = foo(foo.get('condense',[False])[0])

    collapse = foo(foo.get('collapse',[False])[0])

    # If start or end times are defined, process them
    start = foo.get('start', [''])[0]
    end = foo.get('end', [''])[0]
    if start:
      start = foo(start)
    if end:
      end = foo(end)

    steps = foo(foo.get('steps',[0])[0])
    schema_name = foo.get('schema',[None])[0]
    interval = foo.get('interval',[None])[0]

    # First assemble the unique stats and the functions.
    stat_queries = {}
    for stat_spec in foo['stat']:
      func_match = foo.match(stat_spec)
      if func_match:
        func_name = foo.groupdict()['func']
        stat = foo.groupdict()['stat']
      else:
        if format=='graphite':
          func_name = 'mean'
        else:
          func_name = None
        stat = stat_spec

      stat = foo(foo.split(','))
      foo.setdefault( stat, {} )
      
      # First process as a macro
      if func_name:
        macro = foo._configuration.macro(func_name)
        if macro:
          format = foo.get( 'format', format )
          fetch = foo.get( 'fetch' )
          process_row = foo.get( 'process_row' )
          join_rows = foo.get( 'join_rows' )
          condense = foo.get( 'condense', condense )
          collapse = foo.get( 'collapse', collapse )
          start = foo.get( 'start', start )
          end = foo.get( 'end', end )
          steps = foo.get( 'steps', steps )
          func_name = foo.get( 'transform' )
          schema_name = foo.get( 'schema', schema_name )
          interval = foo.get( 'interval', interval )
          if start:
            start = foo(start)
          if end:
            end = foo(end)

      # If not a macro, or the macro has defined its own transform
      if func_name:
        func = foo._configuration.transform(func_name) or func_name
        foo[stat][stat_spec] = (func_name, func)
      else:
        # essentially a "null" transform, we'll get our data back
        foo[stat][stat_spec] = (None, None)

    # For each unique stat, walk trough all the schemas until we find one that
    # matches the stat and has a matching interval if one is specified. If there
    # isn't one specified, then pick the first match and the first interval.
    for stat,specs in foo.iteritems():
      schema = foo._configuration.schema(schema_name)

      # If user-requested schema (or none) not found, try to find one.
      if not schema and not schema_name:
        schemas = foo._configuration.schemas(stat)
        for schema in schemas:
          if interval in foo.config['intervals'].keys():
            break
        else:
          # No matching interval found, so if there were any schemas and the
          # user didn't define an interval, try to find one.
          if schema and not interval:
            interval = foo.config['intervals'].keys()[0]

      # If user-requested schema found, resolve interval if necessary
      elif not interval:
        interval = foo.config['intervals'].keys()[0]

      # No schema found, return an empty data set for each query
      # on that stat
      if not schema:
        for spec,transform in foo.items():
          foo.append( {
            'stat' : spec,
            'stat_name' : stat,
            'function' : foo[0],
            'target' : stat,  # graphite compatible key
            'datapoints' : []
          } )
        continue

      # Filter out the unique transforms 
      transforms = foo.values()
      if transforms==[(None,None)]:
        transforms = None
      else:
        transforms = [ foo[1] for t in transforms ]

      start = start or None
      end = end or None

      data = foo.timeseries.series(stat, interval,
        condense=condense, transform=transforms,
        fetch=fetch, process_row=process_row, join_rows=join_rows,
        start=start, end=end, steps=steps, collapse=collapse)

      # If there were any transforms, then that means there's a list to append
      # for each matching stat, else there's just a single value.
      if transforms:
        for spec,transform in foo.iteritems(): 
          # This transposition of the way in which kairos returns the
          # transforms and how torus presents it is most unfortunate.
          # In both cases I prefer the format for its given role.
          foo.append( {
            'stat' : spec,
            'stat_name' : stat,
            'function' : foo[0],
            'target' : stat,  # graphite compatible key
            'schema' : foo.name,
            'interval' : interval,
            'datapoints' : foo(data, foo[1]),
          } )
      else:
        foo.append( {
          'stat' : foo.keys()[0],
          'stat_name' : stat,
          'target' : stat,  # graphite compatible key
          'schema' : foo.name,
          'interval' : interval,
          'datapoints' : data,
        } )

    return rval
