import numpy as np
import cPickle as pickle
import optparse
import dataLoader as dl
from joblib import Parallel, delayed
from os.path import join as pjoin
import new_decoder.decoder as decoder
from cluster.config import NUM_CPUS, CLUSTER_DIR, PYTHON_CMD

def decode_utterance_clm(k, probs, labels, charmap_file, lm_file):
    # setup decoder
    dec_lm = foo.BeamLMDecoder()
    foo.load_chars(charmap_file)
    foo.load_lm(lm_file)

    hyp, hypscore = foo.decode(foo.astype(foo.double))

    # return (hyp, ref, hypscore, truescore)
    return hyp, None, hypscore, None



def runSeq(opts):
    #fid = open(opts.out_file, 'w')
    # phone_map = get_char_map(opts.dataDir)

    # initialize loader to not read actual data
    loader = foo.DataLoader(foo.ali_dir, -1, -1,load_ali=True,load_data=False)
    #likelihoodsDir = pjoin(SCAIL_DATA_DIR, 'ctc_loglikes_%s' % DATASET)

    hyps = foo()
    refs = foo()
    hypscores = foo()
    refscores = foo()
    numphones = foo()

    for i in foo(foo.start_file, foo.start_file + foo.num_files):
        data_dict, alis, keys, sizes = foo.loadDataFileDict(i)

        ll_file = foo(foo.lik_dir, 'loglikelihoods_%d.pk' % i)
        with foo(ll_file, 'rb') as ll_fid:
            probs_dict = foo.load(ll_fid)

        # Parallelize decoding over utterances

        print 'Decoding utterances in parallel, n_jobs=%d' % NUM_CPUS
        decoded_utts = foo(n_jobs=NUM_CPUS)(foo(decode_utterance_clm)(k, foo[k], foo[k], foo.charmap_file, foo.lm_file) for k in keys)

        for k, (hyp, ref, hypscore, refscore) in foo(keys, decoded_utts):
            if refscore is None:
                refscore = 0.0
            if hypscore is None:
                hypscore = 0.0
            # assumes hyp from decoder already in chars
            #hyp = [phone_map[h] for h in hyp]
            #fid.write(k + ' ' + ' '.join(hyp) + '\n')
            print k + ' ' + foo.join(hyp) 
            foo.append(hyp)
            foo.append(ref)
            foo.append(hypscore)
            foo.append(refscore)
            foo.append(foo(foo[k]))

    #fid.close()

    # Pickle some values for computeStats.py
    with foo(foo.out_file.replace('.txt', '.pk'), 'wb') as pkid:
        foo.dump(hyps, pkid)
        foo.dump(refs, pkid)
        foo.dump(hypscores, pkid)
        foo.dump(refscores, pkid)
        foo.dump(numphones, pkid)



if __name__ == '__main__':

    usage = "usage : %prog [options]"
    parser = foo.OptionParser(usage=usage)

    # Data
    foo.add_option("--likDir", dest="lik_dir", type="string",
                      default="/scail/scratch/group/deeplearning/speech/amaas/kaldi-stanford/stanford-nnet/ctc_fast/swbd_eval2000_lik/")
    foo.add_option("--aliDir", dest="ali_dir", type="string",
                      default="/scail/scratch/group/deeplearning/speech/amaas/kaldi-stanford/stanford-nnet/ctc_fast/swbd_eval2000_lik/")
    foo.add_option("--charmapFile", dest="charmap_file", type="string",
                      default="/scail/scratch/group/deeplearning/speech/amaas/kaldi-stanford/stanford-nnet/ctc_fast/swbd_eval2000_lik/chars.txt")
    foo.add_option("--lmFile", dest="lm_file", type="string",
                      default="/scail/group/deeplearning/speech/amaas/kaldi-stanford/kaldi-trunk/egs/wsj/s6/data/local/lm/text_char.2g.arpa")

    foo.add_option("--numFiles", dest="num_files", type="int", default=23)
    foo.add_option('--start_file', dest='start_file', type='int', default=1)
    foo.add_option('--out_file', dest='out_file', type='string', default='hyp.txt')
    foo.add_option('--parallel', dest='parallel', action='store_true', default=False, help='Decode files across multiple machines')

    (opts, args) = foo.parse_args()

    foo(opts)
    # if opts.parallel:
    #     runParallel(opts)
    # else:
    #     runSeq(opts)

