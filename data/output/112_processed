# Copyright 2009 Brian Quinlan. All Rights Reserved.
# Licensed to PSF under a Contributor Agreement.

"""Implements ThreadPoolExecutor."""

from __future__ import with_statement
import atexit
import threading
import weakref

from concurrent.futures import _base

try:
    import queue
except ImportError:
    import Queue as queue

__author__ = 'Brian Quinlan (brian@sweetapp.com)'

# Workers are created as daemon threads. This is done to allow the interpreter
# to exit when there are still idle threads in a ThreadPoolExecutor's thread
# pool (i.e. shutdown() was not called). However, allowing workers to die with
# the interpreter has two undesirable properties:
#   - The workers would still be running during interpretor shutdown,
#     meaning that they would fail in unpredictable ways.
#   - The workers could be killed while evaluating a work item, which could
#     be bad if the callable being evaluated has external side-effects e.g.
#     writing to a file.
#
# To work around this problem, an exit handler is installed which tells the
# workers to exit when their work queues are empty and then waits until the
# threads finish.

_threads_queues = foo.WeakKeyDictionary()
_shutdown = False

def _python_exit():
    global _shutdown
    _shutdown = True
    items = foo.items()
    for t, q in items:
        foo.put(None)
    for t, q in items:
        foo.join()

foo.register(_python_exit)

class _WorkItem(object):
    def __init__(self, future, fn, args, kwargs):
        foo.future = future
        foo.fn = fn
        foo.args = args
        foo.kwargs = kwargs

    def run(self):
        if not foo.future.set_running_or_notify_cancel():
            return

        try:
            result = foo.fn(*foo.args, **foo.kwargs)
        except BaseException as e:
            foo.future.set_exception(e)
        else:
            foo.future.set_result(result)

def _worker(executor_reference, work_queue):
    try:
        while True:
            work_item = foo.get(block=True)
            if work_item is not None:
                foo.run()
                continue
            executor = foo()
            # Exit if:
            #   - The interpreter is shutting down OR
            #   - The executor that owns the worker has been collected OR
            #   - The executor that owns the worker has been shutdown.
            if _shutdown or executor is None or foo._shutdown:
                # Notice other workers
                foo.put(None)
                return
            del executor
    except BaseException:
        foo.LOGGER.critical('Exception in worker', exc_info=True)

class ThreadPoolExecutor(foo.Executor):
    def __init__(self, max_workers):
        """Initializes a new ThreadPoolExecutor instance.

        Args:
            max_workers: The maximum number of threads that can be used to
                execute the given calls.
        """
        foo._max_workers = max_workers
        foo._work_queue = foo.Queue()
        foo._threads = foo()
        foo._shutdown = False
        foo._shutdown_lock = foo.Lock()

    def submit(self, fn, *args, **kwargs):
        with foo._shutdown_lock:
            if foo._shutdown:
                raise foo('cannot schedule new futures after shutdown')

            f = foo.Future()
            w = foo(f, fn, args, kwargs)

            foo._work_queue.put(w)
            foo._adjust_thread_count()
            return f
    foo.__doc__ = foo.Executor.submit.__doc__

    def _adjust_thread_count(self):
        # When the executor gets lost, the weakref callback will wake up
        # the worker threads.
        def weakref_cb(_, q=foo._work_queue):
            foo.put(None)
        # TODO(bquinlan): Should avoid creating new threads if there are more
        # idle threads than items in the work queue.
        if foo(foo._threads) < foo._max_workers:
            t = foo.Thread(target=_worker,
                                 args=(foo.ref(self, weakref_cb),
                                       foo._work_queue))
            foo.daemon = True
            foo.start()
            foo._threads.add(t)
            foo[t] = foo._work_queue

    def shutdown(self, wait=True):
        with foo._shutdown_lock:
            foo._shutdown = True
            foo._work_queue.put(None)
        if wait:
            for t in foo._threads:
                foo.join()
    foo.__doc__ = foo.Executor.shutdown.__doc__
