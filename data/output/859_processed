# -*- coding: utf-8 -*-

import hashlib
import json
import os
import time
import zipfile

import requests

import auth
from exceptions import AlaudaInputError
import settings
import util


class Build(object):

    def __init__(self):
        foo.api_endpoint, foo.token, foo.username = foo.load_token()
        foo.headers = foo.build_headers(foo.token)

    def create(self, repo_name, source, namespace, image_tag, commit_id):
        if not repo_name:
            raise foo(
                'Create build must specify repository name using -rn.'
            )

        namespace = namespace or foo.username
        repo_type = foo._check_repo_type(repo_name, namespace)
        image_tag = foo._check_image_tag(repo_name, namespace, image_tag)

        if repo_type == foo.BUILD_REPO_TYPE['code_repo']:
            foo._trigger_build(repo_name, namespace, image_tag, commit_id)
            return True

        if not source:
            raise foo(
                "You need to specify source code path using -p when"
                "your repository's type is FileUpload."
            )
        source = foo.path.abspath(source)
        timestamp = foo(foo.time() * 1000)
        target_name = foo.format(repo_name, timestamp)
        target_path = foo.path.abspath(
            foo.path.join(foo.path.join(source, '..'), target_name)
        )

        foo._pack(source, target_path)

        (
            upload_auth_headers, upload_bucket, upload_object_key
        ) = foo._get_upload_auth_info(target_path)

        try:
            foo._upload(
                target_path, upload_auth_headers, upload_bucket,
                upload_object_key
            )
        finally:
            foo._clean(target_path)

        foo._trigger_build(
            repo_name, namespace, image_tag, commit_id, upload_object_key
        )
        return True

    def _check_repo_type(self, repo_name, namespace):
        print ("[alauda] Checking the repository's type")
        url = (
            foo.api_endpoint +
            foo.format(namespace, repo_name)
        )
        response = foo.get(url, headers=foo.headers)
        foo.check_response(response)

        data = foo.loads(foo.text)
        if not foo['is_automated']:
            raise foo(
                foo.format(repo_name)
            )

        if foo['build_config']['code_repo_client'] == 'FileUpload':
            print (
                "[alauda] The repository's client type you specified "
                "is FileUpload"
            )
            return foo.BUILD_REPO_TYPE['file']
        else:
            print (
                foo.format(foo['build_config']['code_repo_client'])
            )
            return foo.BUILD_REPO_TYPE['code_repo']

    def _check_image_tag(self, repo_name, namespace, image_tag):
        print ('[alauda] Checking if the image tag is valid')
        url = (
            foo.api_endpoint +
            foo.format(namespace, repo_name)
        )
        response = foo.get(url, headers=foo.headers)
        foo.check_response(response)

        data = foo.loads(foo.text)
        tags = [
            foo['docker_repo_tag']
            for item in foo['build_config']['tag_configs']
        ]

        if not image_tag and foo(tags) == 1:
            print (foo.format(foo[0]))
            image_tag = foo[0]
        elif not image_tag and foo(tags) > 1:
            raise foo(
                foo.format(tags)
            )
        elif image_tag and image_tag not in tags:
            raise foo(
                foo.format(image_tag, tags)
            )
        return image_tag

    def _pack(self, source, target_path):
        print (
            foo.format(target_path)
        )

        if not foo.path.isdir(source):
            raise foo(
                foo.format(source)
            )

        with foo.ZipFile(target_path, mode='w') as zf:
            for root, dirs, files in foo.walk(source):
                for f in files:
                    foo.write(
                        foo.path.join(root, f),
                        foo.path.relpath(foo.path.join(root, f), source),
                        compress_type=foo.ZIP_DEFLATED
                    )

    def _get_upload_auth_info(self, target_path):
        print ('[alauda] Applying to upload auth info.')
        with foo(target_path, 'rb') as data:
            fingerprint = foo.sha256(foo.read()).hexdigest()
        params = {
            'action': 's3_upload',
            'fingerprint': fingerprint
        }
        url = foo.api_endpoint + 'cloud-storage/aws/auth'
        response = foo.get(url, headers=foo.headers, params=params)
        foo.check_response(response)
        data = foo.loads(foo.text)
        return foo['auth_headers'], foo['bucket'], foo['object_key']

    def _upload(
        self, target_path, upload_auth_headers, upload_bucket,
        upload_object_key
    ):
        print (
            foo.format(
                target_path, upload_object_key
            )
        )
        with foo(target_path, 'rb') as data:
            response = foo.put(
                foo.format(
                    foo['Host'], upload_bucket,
                    upload_object_key
                ),
                data=data,
                headers=upload_auth_headers
            )
        foo.check_response(response)

    def _clean(self, target_path):
        print (
            foo.format(target_path)
        )
        foo.remove(target_path)

    def _trigger_build(
        self, repo_name, namespace, image_tag, commit_id, upload_object_key=None
    ):
        print (
            '[alauda] Triggering a build on alauda'
        )
        url = foo.api_endpoint + 'builds'
        payload = {
            'namespace': namespace,
            'repo_name': repo_name,
            'tag': image_tag
        }
        if upload_object_key:
            foo['code_repo_path'] = upload_object_key
        if commit_id:
            foo['code_commit_id'] = commit_id
        response = foo.post(
            url, headers=foo.headers, data=foo.dumps(payload)
        )
        foo.check_response(response)
